---
title: "A High-Dimensional View of Neuroscience"
subtitle: "Tutorial session at [Cognitive Computational Neuroscience 2023](https://2023.ccneuro.org/kt3.php)"
abstract: |
    Advances in technology enable us to record neural responses to many thousands of stimuli from a huge number of channels (e.g. fMRI in humans, two-photon imaging in mice, neuropixel probes in monkeys). Given the unprecedented scale of these data -- collected with incredible effort at enormous expense -- what computational tools can we use to study neural representations in high dimensions? What theoretical insights can we gain about the nature of neural representations from large-scale datasets?

abstract-title: Motivation
affiliations:
  - id: jhu
    name: Bonner Lab | Johns Hopkins University
    url: https://cogsci.jhu.edu/
  - id: psl
    name: École normale supérieure  # TODO verify
    url: https://www.ens.psl.eu/en/ens

author:
  - name: Atlas Kazemian
    url: https://akazemian.github.io/personal_profile/
    email: akazemi3@jh.edu
    orcid: 0000-0001-7699-2964
    affiliation:
      - ref: jhu
  - name: Raj Magesh Gauthaman
    url: https://cogsci.jhu.edu/directory/raj-gauthaman/  # TODO update
    email: rgautha1@jh.edu
    orcid: 0000-0001-7121-1532
    affiliation:
      - ref: jhu
  - name: Zirui Chen
    url: https://cogsci.jhu.edu/directory/zirui-chen/  # TODO update
    email: zchen160@jh.edu
    orcid: 0000-0003-3666-1719
    affiliation:
      - ref: jhu
  - name: Florentin Guth
    url: TODO  # TODO update
    email: TODO@TODO  # TODO update
    orcid: 0000-0000-0000-0000  # TODO update
    affiliation:
      - ref: psl
  - name: Michael Bonner
    url: https://bonnerlab.org/
    email: mfbonner@jhu.edu
    orcid: 0000-0002-4992-674X
    affiliation:
      - ref: jhu

format:
  html:
    code-tools:
      source: false
      toggle: false
    title-block-style: default
    toc: false
---

## Welcome!

This site contains material for a [tutorial](https://2023.ccneuro.org/kt3.php) presented at the conference on [Cognitive Computational Neuroscience 2023](https://2023.ccneuro.org/).

::: {.callout-important}
# Don't miss the tutorial!

Where
: East Schools

When
: Saturday, August 26, 2023 @ 10:45 - 12:30
:::

## Outline

This tutorial is broadly divided into four parts:

1. An introduction to PCA [[website](https://bonnerlab.github.io/ccn-tutorial/pages/introducing_pca.html), [Colab](https://colab.research.google.com/github/BonnerLab/ccn-tutorial/blob/main/notebooks/introducing_pca.ipynb), [download](https://bonnerlab.github.io/ccn-tutorial/pages/introducing_pca.ipynb)]
2. Exploring a neural dataset [[website](https://bonnerlab.github.io/ccn-tutorial/pages/exploring_neural_data.html), [Colab](https://colab.research.google.com/github/BonnerLab/ccn-tutorial/blob/main/notebooks/exploring_neural_data.ipynb), [download](https://bonnerlab.github.io/ccn-tutorial/pages/exploring_neural_data.ipynb)]
3. Dealing with noisy data [[website](https://bonnerlab.github.io/ccn-tutorial/pages/dealing_with_noise.html), [Colab](https://colab.research.google.com/github/BonnerLab/ccn-tutorial/blob/main/notebooks/dealing_with_noise.ipynb), [download](https://bonnerlab.github.io/ccn-tutorial/pages/dealing_with_noise.ipynb)]
4. Comparing high-dimensional representations [[website](https://bonnerlab.github.io/ccn-tutorial/pages/comparing_representations.html), [Colab](https://colab.research.google.com/github/BonnerLab/ccn-tutorial/blob/main/notebooks/comparing_representations.ipynb), [download](https://bonnerlab.github.io/ccn-tutorial/pages/comparing_representations.ipynb)]

## Instructions

The [computational notebooks](https://docs.jupyter.org/en/latest/index.html) contain some fun interactive elements and are designed to be run on [Google Colab](https://colab.research.google.com/) -- just follow the links above!

If you can't run the notebooks, don't worry -- just follow along on the website!

::: {.callout-note collapse="true"}
# If you'd prefer to run the notebooks locally...

Create a [Python virtual environment](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment) with `Python >=3.10.12` to run the notebooks. The required dependencies will be automatically installed when you run the first cell of each notebook.
:::

::: {.callout-tip}
# Notice a typo? Have some feedback?

Use the `Report an issue` button on the sidebar of each page to contact us! Feel free to suggest edits by using the `Edit this page` button too!
:::

## Acknowledgments {.appendix}

Thanks to the [Natural Scene Dataset](http://naturalscenesdataset.org/) team for letting use a part of the dataset for this tutorial!

Thanks to the Open Science Foundation for hosting the [data files](https://osf.io/zk265/) for this tutorial!
