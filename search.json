[
  {
    "objectID": "pages/reference.html",
    "href": "pages/reference.html",
    "title": "Reference",
    "section": "",
    "text": "A scalar is a single real number.\nExamples:\n\n0\n1\n\\pi\n-3.5\n\n\n\n\nAn n-vector is a collection of n real numbers.\nExamples:\n\nA 1-vector: \\begin{bmatrix}5\\end{bmatrix}\nA 3-vector: \\begin{bmatrix}2\\\\-4.5\\\\\\pi\\end{bmatrix}\nAn n-vector: \\begin{bmatrix}3\\\\\\vdots\\\\-1\\end{bmatrix} (it has n elements, trust me)\nA row vector\n\n\n\n\nAn m \\times n matrix is a collection of"
  },
  {
    "objectID": "pages/reference.html#the-basics",
    "href": "pages/reference.html#the-basics",
    "title": "Reference",
    "section": "",
    "text": "A scalar is a single real number.\nExamples:\n\n0\n1\n\\pi\n-3.5\n\n\n\n\nAn n-vector is a collection of n real numbers.\nExamples:\n\nA 1-vector: \\begin{bmatrix}5\\end{bmatrix}\nA 3-vector: \\begin{bmatrix}2\\\\-4.5\\\\\\pi\\end{bmatrix}\nAn n-vector: \\begin{bmatrix}3\\\\\\vdots\\\\-1\\end{bmatrix} (it has n elements, trust me)\nA row vector\n\n\n\n\nAn m \\times n matrix is a collection of"
  },
  {
    "objectID": "pages/reference.html#matrix-decompositions",
    "href": "pages/reference.html#matrix-decompositions",
    "title": "Reference",
    "section": "Matrix decompositions",
    "text": "Matrix decompositions\n\nSingular value decomposition\nThe singular value decomposition (SVD) involves rewriting a matrix X \\in \\mathbb{R}^{m \\times n} as the product of three matrices X = U \\Sigma V^\\top, where\n\nU \\in \\mathbb{R}^{m \\times m} and V \\in \\mathbb{R}^{n \\times n} are orthonormal matrices and\n\\Sigma \\in \\mathbb{R}^{m \\times n} is zero everywhere except potentially on its main diagonal.\n\n\n\nEigendecomposition\nThe eigendecomposition of a symmetric matrix X \\in \\mathbb{R}^{n \\times n} involves rewriting it as the product of three matrices X = V \\Lambda V^\\top, where\n\nV \\in \\mathbb{n \\times n} is orthonormal and\n\\Lambda \\in \\mathbb{n \\times n} is diagonal with non-negative entries."
  },
  {
    "objectID": "pages/reference.html#covariance",
    "href": "pages/reference.html#covariance",
    "title": "Reference",
    "section": "Covariance",
    "text": "Covariance\n\nAuto-covariance\nGiven a data matrix X \\in \\mathbb{R}^{n \\times f} containing neural responses to n stimuli from f neurons, the auto-covariance of X (or simply its covariance) is defined as:\n\\text{cov}(X) = \\left(\\dfrac{1}{n - 1}\\right) (X - \\overline{X})^\\top (X - \\overline{X})\nThis is an f \\times f matrix where the (i, j)-th element measures how much neuron i covaries with neuron j. If the covariance is positive, they tend to have similar activation: a stimulus that activates one neuron will tend to activate the other. If the covariance is negative, the neurons will have dissimilar activation: a stimulus that activates one neuron will likely decrease the activity of the other.\n\n\nCross-covariance\nGiven two data matrices X \\in \\mathbb{R}^{n \\times f_X} and Y \\in \\mathbb{R}^{n \\times f_Y} containing neural responses to n stimuli from f_X and f_Y neurons respectively, the cross-covariance of X and Y is defined as:\n\\text{cov}(X, Y) = \\left(\\dfrac{1}{n - 1}\\right) (X - \\overline{X})^\\top (Y - \\overline{Y})"
  },
  {
    "objectID": "pages/reference.html#correlation",
    "href": "pages/reference.html#correlation",
    "title": "Reference",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "pages/exploring_neural_data.html",
    "href": "pages/exploring_neural_data.html",
    "title": "Exploring a neural dataset",
    "section": "",
    "text": "Run this notebook interactively!\n\n\n\nHere’s a link to this notebook on Google Colab.\nInstall all required dependencies\n# TODO uncomment before final packaging\n# %pip install git+https://github.com/BonnerLab/ccn-tutorial.git\nImport various libraries\nfrom pathlib import Path\nimport requests\nimport typing\nimport warnings\n\nfrom loguru import logger\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nimport nibabel as nib\nimport nilearn.plotting\nfrom PIL import Image\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA, NMF\nfrom umap import UMAP\n\nimport matplotlib as mpl\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom matplotlib import pyplot as plt\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox\nimport seaborn as sns\nfrom IPython.display import display\n\nfrom utilities.brain import (\n    load_dataset,\n    average_data_across_repetitions,\n    load_stimuli,\n    plot_brain_map,\n)\nSet some visualization defaults\n%matplotlib inline\n\nsns.set_theme(\n    context=\"notebook\",\n    style=\"white\",\n    palette=\"deep\",\n    rc={\"legend.edgecolor\": \"None\"},\n)\nset_matplotlib_formats(\"svg\")\n\npd.set_option(\"display.max_rows\", 5)\npd.set_option(\"display.max_columns\", 10)\npd.set_option(\"display.precision\", 3)\npd.set_option(\"display.show_dimensions\", False)\n\nxr.set_options(display_max_rows=3, display_expand_data=False)\n\nwarnings.filterwarnings(\"ignore\")\nInitialize a deterministic random number generator\nrandom_state = 0\nrng = np.random.default_rng(seed=random_state)"
  },
  {
    "objectID": "pages/exploring_neural_data.html#the-natural-scenes-fmri-dataset-nsd",
    "href": "pages/exploring_neural_data.html#the-natural-scenes-fmri-dataset-nsd",
    "title": "Exploring a neural dataset",
    "section": "The Natural Scenes fMRI Dataset (NSD)",
    "text": "The Natural Scenes fMRI Dataset (NSD)\n\nNSD is the largest fMRI dataset on human vision, with 7T fMRI responses (1.8mm isotropic voxels) obtained from 8 adult participants. The experiment involved a continuous recognition task while participants observed natural scene images from the Microsoft Common Objects in Context (COCO) database (Lin et al., 2014).\nLet’s load the dataset. This data contains neural responses to 872 images from ~15,000 voxels reliably modulated by the visual stimuli during the NSD experiment.\n\n\nLoad the dataset\ndata = average_data_across_repetitions(load_dataset(subject=0, roi=\"general\"))\n\ndisplay(data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'fMRI betas' (presentation: 700, neuroid: 15724)&gt;\n0.4915 0.2473 0.08592 0.05828 -0.1315 ... -0.2126 -0.6315 -0.5751 -0.5354\nCoordinates: (3/4)\n    x            (neuroid) uint8 12 12 12 12 12 12 12 ... 71 72 72 72 72 72 72\n    y            (neuroid) uint8 21 22 22 22 22 22 23 ... 34 29 29 30 30 30 31\n    ...           ...\n    stimulus_id  (presentation) object 'image02950' ... 'image72948'\nDimensions without coordinates: presentation, neuroid\nAttributes: (3/8)\n    resolution:      1pt8mm\n    preprocessing:   fithrf_GLMdenoise_RR\n    ...              ...\n    postprocessing:  averaged across first two repetitionsxarray.DataArray'fMRI betas'presentation: 700neuroid: 157240.4915 0.2473 0.08592 0.05828 ... -0.2126 -0.6315 -0.5751 -0.5354array([[ 0.4915219 ,  0.24733381,  0.08592446, ..., -0.366651  ,\n         0.30723202,  0.43520752],\n       [ 0.1664538 , -0.10728736,  0.35630295, ...,  0.8608913 ,\n         0.03464809,  0.11020081],\n       [ 1.0357349 ,  0.77598304,  0.35813144, ...,  0.2419075 ,\n         0.81557286,  0.38667244],\n       ...,\n       [-0.05812129, -0.4539395 ,  0.41060364, ...,  0.5738151 ,\n        -0.718189  , -0.638827  ],\n       [-0.00340644, -1.0050421 ,  0.7278904 , ...,  0.580743  ,\n        -0.50856245, -0.2727615 ],\n       [-1.2668517 , -1.4769105 , -0.3562023 , ..., -0.63146234,\n        -0.575121  , -0.5354325 ]], dtype=float32)Coordinates: (4)x(neuroid)uint812 12 12 12 12 ... 72 72 72 72 72array([12, 12, 12, ..., 72, 72, 72], dtype=uint8)y(neuroid)uint821 22 22 22 22 ... 29 30 30 30 31array([21, 22, 22, ..., 30, 30, 31], dtype=uint8)z(neuroid)uint847 45 46 47 48 ... 46 45 46 49 49array([47, 45, 46, ..., 46, 49, 49], dtype=uint8)stimulus_id(presentation)object'image02950' ... 'image72948'array(['image02950', 'image02990', 'image03049', 'image03077',\n       'image03146', 'image03157', 'image03164', 'image03171',\n       'image03181', 'image03386', 'image03434', 'image03449',\n       'image03489', 'image03626', 'image03682', 'image03687',\n       'image03729', 'image03809', 'image03842', 'image03847',\n       'image03856', 'image03913', 'image03951', 'image04051',\n       'image04058', 'image04129', 'image04156', 'image04249',\n       'image04423', 'image04436', 'image04667', 'image04690',\n       'image04768', 'image04786', 'image04835', 'image04892',\n       'image04930', 'image05034', 'image05106', 'image05204',\n       'image05301', 'image05338', 'image05459', 'image05542',\n       'image05583', 'image05602', 'image05714', 'image06199',\n       'image06222', 'image06431', 'image06444', 'image06489',\n       'image06514', 'image06521', 'image06558', 'image06801',\n       'image07007', 'image07039', 'image07120', 'image07207',\n       'image07366', 'image07418', 'image07480', 'image07654',\n       'image07840', 'image07859', 'image07944', 'image07948',\n       'image08006', 'image08109', 'image08204', 'image08225',\n       'image08394', 'image08415', 'image08435', 'image08465',\n       'image08509', 'image08646', 'image08807', 'image08843',\n...\n       'image64615', 'image64621', 'image64867', 'image64880',\n       'image65010', 'image65148', 'image65253', 'image65267',\n       'image65376', 'image65445', 'image65769', 'image65799',\n       'image65821', 'image65872', 'image65920', 'image65943',\n       'image66004', 'image66216', 'image66278', 'image66330',\n       'image66464', 'image66489', 'image66580', 'image66773',\n       'image66836', 'image66946', 'image66976', 'image67045',\n       'image67113', 'image67204', 'image67237', 'image67295',\n       'image67742', 'image67802', 'image67829', 'image68168',\n       'image68278', 'image68339', 'image68418', 'image68471',\n       'image68741', 'image68814', 'image68842', 'image68858',\n       'image68897', 'image69007', 'image69130', 'image69214',\n       'image69240', 'image69502', 'image69614', 'image69839',\n       'image69854', 'image70075', 'image70095', 'image70193',\n       'image70232', 'image70335', 'image70360', 'image70427',\n       'image70505', 'image71229', 'image71232', 'image71241',\n       'image71410', 'image71450', 'image71753', 'image71894',\n       'image72015', 'image72080', 'image72209', 'image72312',\n       'image72510', 'image72605', 'image72719', 'image72948'],\n      dtype=object)Indexes: (0)Attributes: (8)resolution :1pt8mmpreprocessing :fithrf_GLMdenoise_RRz_score :Trueroi :generalsubject :0brain shape :[ 81 104  83]citation :Allen, E.J., St-Yves, G., Wu, Y. et al. A massive 7T fMRI dataset to bridge cognitive neuroscience and artificial intelligence. Nat Neurosci 25, 116-126 (2022). https://doi.org/10.1038/s41593-021-00962-xpostprocessing :averaged across first two repetitions\n\n\n\n\n\n\n\n\nSome fMRI preprocessing details\n\n\n\nWe utilized the NSD single-trial betas, preprocessed in 1.8 mm volumetric space and denoised using the GLMdenoise technique (version 3;“betas_fithrf_GLMdenoise_RR”). The betas were converted to Z-scores within each scanning session and averaged across repetitions for each stimulus.\n\n\nHere are some examples of stimuli that we analyzed.\n\n\nLoad the stimuli\ndef view_stimuli(stimuli: xr.DataArray, *, n: int = 10) -&gt; None:\n    fig = plt.figure(figsize=(12, 4))\n    image_grid = ImageGrid(\n        fig=fig,\n        rect=(1, 1, 1),\n        nrows_ncols=(1, n),\n        share_all=True,\n    )\n    for i_image in range(n):\n        image_grid[i_image].imshow(stimuli[i_image])\n        image_grid[i_image].axis(\"off\")\n    fig.show()\n\n\nstimuli = load_stimuli()\nview_stimuli(stimuli)\n\n\n\n\n\n\n\n\n\n\nThe neural eigenspectrum\nNow we can apply PCA to the neural responses and plot the eigenspectrum of the data!\n\n\nVisualize the eigenspectrum\ndef view_eigenspectrum(pca: PCA, *, log: bool = False) -&gt; None:\n    eigenvalues = pd.DataFrame(pca.explained_variance_, columns=[\"eigenvalue\"]).assign(\n        rank=1 + np.arange(pca.n_components_)\n    )\n\n    fig, ax = plt.subplots(figsize=(6, 6))\n    sns.lineplot(\n        ax=ax,\n        data=eigenvalues.loc[eigenvalues[\"rank\"] &lt; pca.n_components_],\n        x=\"rank\",\n        y=\"eigenvalue\",\n    )\n    sns.despine(ax=ax)\n    if log:\n        ax.set_xscale(\"log\")\n        ax.set_yscale(\"log\")\n        ax.set_ylim(bottom=1)\n    fig.show()\n\n\npca = PCA()\npca.fit(data)\n\nview_eigenspectrum(pca)\n\n\n\n\n\nNeural eigenspectra with linear scaling\n\n\n\n\nOn this plot, the first few PCs have substantial variance while there appears to be negligible variance after about rank 20. How can we interpret these PCs of different variance levels? There are some simple ways to visualize these PCs.\n\nVisualizing principal components\n\n\nUtilities to view images\ndef view_images_as_scatterplot(\n    x: np.ndarray, y: np.ndarray, *, stimuli: xr.DataArray\n) -&gt; None:\n    fig, ax = plt.subplots(figsize=(10, 10))\n    for i_stimulus in range(len(stimuli)):\n        image_box = OffsetImage(stimuli[i_stimulus].values, zoom=0.3)\n        image_box.image.axes = ax\n\n        ab = AnnotationBbox(\n            image_box,\n            xy=(x[i_stimulus], y[i_stimulus]),\n            xycoords=\"data\",\n            frameon=False,\n            pad=0,\n        )\n        ax.add_artist(ab)\n\n    ax.set_xlim([x.min(), x.max()])\n    ax.set_ylim([y.min(), y.max()])\n    ax.axis(\"off\")\n    fig.show()\n\n\ndef view_images_at_poles(\n    x: np.ndarray,\n    *,\n    stimuli: xr.DataArray,\n    n_images_per_pole: int = 5,\n    label: str | None = None,\n) -&gt; None:\n    indices = np.argsort(x, axis=0)\n\n    fig = plt.figure(figsize=(12, 4))\n    image_grid = ImageGrid(\n        fig=fig,\n        rect=(1, 1, 1),\n        nrows_ncols=(1, 2 * n_images_per_pole + 1),\n        share_all=True,\n    )\n    for i_image in range(n_images_per_pole):\n        image_grid[i_image].imshow(stimuli[indices[i_image]])\n        image_grid[i_image].axis(\"off\")\n        image_grid[-i_image - 1].imshow(stimuli[indices[-i_image - 1]])\n        image_grid[-i_image - 1].axis(\"off\")\n\n    for ax in image_grid:\n        ax.axis(\"off\")\n\n    if label is not None:\n        ax = image_grid[n_images_per_pole]\n        ax.text(\n            0.5,\n            0.5,\n            label,\n            horizontalalignment=\"center\",\n            verticalalignment=\"center\",\n            transform=ax.transAxes,\n        )\n    fig.show()\n\n\nThe first method is to plot the stimuli on a scatter plot, designating their X and Y coordinates to be their scores along two PCs of interest. This allows us to observe potential clustering of the stimuli.\n\n\nProject the neural data onto the first two principal components\ndata_pca = pca.transform(data)\nview_images_as_scatterplot(data_pca[:, 0], data_pca[:, 1], stimuli=stimuli)\n\n\n\n\n\n\n\n\n\nAlternativley, we can focus on the stimuli with the highest or lowest scores along a given PC. It provides simple clues of what this PC might be sensitive to, which could be features ranging from low to high complexity level.\n\n\nView images that have extreme scores on the PCs\nfor rank in [1, 2, 3, 10, 50, 100]:\n    view_images_at_poles(data_pca[:, rank - 1], stimuli=stimuli, label=f\"rank {rank}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat about other methods?\n\n\n\n\n\nInterpreting PCs can be challenging especially when we rely solely on visual inspection. This difficulty arises, in part, because many natural features are non-negative. As a result, methods like nonnegative matrix factorization (NMF) often offer more interpretable dimensions than PCA.\n\n\nCompute NMF of neural responses\nscaler = MinMaxScaler()\nscaler.fit(data)\n\nnmf = NMF(n_components=2, random_state=random_state)\ndata_nmf = nmf.fit_transform(scaler.transform(data))\n\nview_images_as_scatterplot(data_nmf[:, 0], data_nmf[:, 1], stimuli=stimuli)\n\n\n\n\n\n\n\n\n\nSimilarly, we can inspect the stimuli with highest or closest-to-zero values along each dimension.\n\n\nView images that have extreme scores on the dimensions\nfor dim in range(2):\n    view_images_at_poles(data_pca[:, dim], stimuli=stimuli, label=f\"dim {dim+1}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNonetheless, PCA has unique benefits that shouldn’t be overlooked. For instance, PCA offers closed-form solutions and non-stochastic outcomes. They’re also well characterized mathematically. Moreover, because PCA is essentially rotateing data to present it in a clearer perspective, it is able to preserve all the original information.\n\n\n\n\n\nLogarithmic scale\nGiven these visualization, we might deem that the higher-rank PCs are non-interpretable and thus follow the common practice to drop them. However, before doing so, let’s try visualizing the spectrum on a logarithmic scale for both axes:\n\n\nVisualize the eigenspectrum on a logarithmic scale\nview_eigenspectrum(pca, log=True)\n\n\n\n\n\nNeural eigenspectra with logarithmic scaling\n\n\n\n\nOn a log-log scale, the spectrum shows no obvious discontinuity! This suggests that the neural population code has a scale-free structure and its latent dimensionality is likely higher than 20!\nWhat kind of structure is this? We observe that the spectrum is approximately linear on this log-log scale, suggesting that the eigenvalues obey a power law:\n\\log{\\lambda_\\text{rank}} \\approx \\alpha \\log{\\left( \\text{rank} \\right)} + c \\implies \\lambda_\\text{rank} \\propto \\left( \\text{rank} \\right)^\\alpha\n\n\nPower laws\nA power law is a relationship of the form f(x) \\propto x^{\\alpha}, where \\alpha is termed the index of the power law, or the power law exponent.\nPower laws are ubiquitious in nature, arising in all sorts of systems:\n\nword frequencies in natural language (Zipf’s law)\nwealth distribution (Pareto principle)\nferromagnetism (Ising model)\n\nPower laws are scale-free: f(kx) \\propto f(x).\n\nbonus: phase transitions at critical power-law exponent\n\ne.g. Curie temperature of ferromagnetic substances\n\nbonus: self-organizing systems\n\n\n\n\nSome nonlinear methods\n\nNonnegative matrix factorization (NMF)\n\n\nCompute NMF of neural responses\nscaler = MinMaxScaler()\nscaler.fit(data)\n\nnmf = NMF(n_components=2, random_state=random_state)\ndata_nmf = nmf.fit_transform(scaler.transform(data))\n\nview_images_as_scatterplot(data_nmf[:, 0], data_nmf[:, 1], stimuli=stimuli)\n\n\n\n\n\n\n\n\n\n\n\nUniform Manifold Approximation & Projection (UMAP)\n\n\nCompute UMAP projection of neural responses\numap = UMAP(n_components=2, metric=\"euclidean\", random_state=random_state)\ndata_umap = umap.fit_transform(data)\n\nview_images_as_scatterplot(data_umap[:, 0], data_umap[:, 1], stimuli=stimuli)\n\n\n\n\n\nUMAP projection of neural data\n\n\n\n\nBenefits of linear methods\n\nclosed form solutions\nnon-stochastic\nwell-characterized mathematically\npreserves all the info in data (just a rotation, different view of the data)\n\nAs you will see, there are cool methods to get stimulus-dependent variance using linear methods: not obvious with NMF, etc."
  },
  {
    "objectID": "pages/dealing_with_noise.html",
    "href": "pages/dealing_with_noise.html",
    "title": "Dealing with noisy data",
    "section": "",
    "text": "Run this notebook interactively!\n\n\n\nHere’s a link to this notebook on Google Colab.\nInstall all required dependencies\n# TODO uncomment before final packaging\n# %pip install git+https://github.com/BonnerLab/ccn-tutorial.git\nImport various libraries\nfrom collections.abc import Sequence\nimport functools\nimport warnings\nfrom typing import NamedTuple\n\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\nimport ipywidgets as widgets\nfrom IPython.display import display\n\nfrom utilities.brain import load_dataset\n\nfrom utilities.computation import assign_logarithmic_bins\nSet some visualization defaults\n%matplotlib inline\n\nsns.set_theme(\n    context=\"notebook\",\n    style=\"white\",\n    palette=\"deep\",\n    rc={\"legend.edgecolor\": \"None\"},\n)\nset_matplotlib_formats(\"svg\")\n\npd.set_option(\"display.max_rows\", 5)\npd.set_option(\"display.max_columns\", 10)\npd.set_option(\"display.precision\", 3)\npd.set_option(\"display.show_dimensions\", False)\n\nxr.set_options(display_max_rows=3, display_expand_data=False)\n\nwarnings.filterwarnings(\"ignore\")\nInitialize a deterministic random number generator\nrandom_state = 0\nrng = np.random.default_rng(seed=random_state)"
  },
  {
    "objectID": "pages/dealing_with_noise.html#neural-data-is-noisy",
    "href": "pages/dealing_with_noise.html#neural-data-is-noisy",
    "title": "Dealing with noisy data",
    "section": "Neural data is noisy",
    "text": "Neural data is noisy\nExperimental data is noisy – often fundamentally. When we measure neural activity in response to a stimulus, our recordings comprise several sources of variation:\n\nintrinsic stochasticity in the system – e.g. the stochastic spiking of neurons\nmeasurement noise\n\ne.g.scanner drift in fMRI\ne.g. poor electrode scalp contact in EEG\n\ncross-trial variation – i.e. recording responses to the same stimuli from the same animal on multiple days\n\ne.g. when your participant has coffee in the morning before a long scanning session\ne.g. in brain-computer intefaces, where representational shifts require the system to be recalibrated frequently\n\ncross-individual differences – i.e. recording from different participants in an experiment\nstimulus-dependent signal\n\ne.g. face-selective neurons in the fusiform face area responding more to faces than houses\n\n\nOf these sources of variation, when investigating a sensory system, we are typically interested in the last one – how the neural response varies with the stimulus.\n\nTruncating spectra might ignore low-variance signal!\nIn the last section, we observed that neural responses have high-dimensional structure, as evidenced by the covariance spectrum obtained from principal component analysis. How much of this variance is driven by stimulus-dependent signal – and how much is noise? The typical assumption when applying principal component analysis as a dimensionality reduction tool is that high-variance dimensions correspond to signal in the system, while low-variance dimensions represent noise. However, there is no fundamental reason this has to be the case!\nFor example, consider a very realistic scenario where a participant gets bored performing our experiment inside an fMRI scanner and starts yodeling to entertain themselves. The highest variance components in the measured neural response would likely be motion artifacts and not whatever signal we were interested in measuring. A high-quality data preprocessing pipeline would help mitigate such extreme components of variance – but cannot remove them entirely!\nIn fact, as we saw when we inspected the first couple of latent dimensions in our toy example, the principal components didn’t correspond directly to the latent variables generating the data; rather, they were a mixture of stimulus-dependent variance and nuisance variance.\nThis suggests that using principal component analysis as a dimensionality reduction tool by setting an arbitrary variance threshold is likely too stringent a criterion: there is possible low-variance signal along the many neglected dimensions in the tail!\nClearly, we need a different approach to using the spectrum to separate signal and noise…\n\n\n\n\n\n\nThe covariance structure of random matrices\n\n\n\n\n\nEven random matrices have some covariance structure that result in non-zero eigenvalues. This structure has been mathematically characterized by the Marchenko-Pastur distribution. This makes it especially difficult to infer anything about the reliability or significance of the dimension from the magnitude of the eigenvalue – especially when the eigenvalues are close to zero.\n\n\nVisualize the covariance eigenspectra of random matrices\ndef simulate_marchenko_pastur(\n    n_stimuli: int = 500,\n    n_neurons: int = 500,\n    n_repetitions: int = 50,\n) -&gt; np.ndarray:\n    data = rng.standard_normal((n_repetitions, n_stimuli, n_neurons))\n    data -= data.mean(axis=-2, keepdims=True)\n\n    singular_values = np.linalg.svd(data, compute_uv=False)\n    return (\n        xr.DataArray(\n            name=\"eigenvalue\",\n            data=singular_values**2 / (n_stimuli - 1),\n            dims=(\"repetition\", \"rank\"),\n            coords={\"rank\": (\"rank\", 1 + np.arange(singular_values.shape[-1]))},\n        )\n        .to_dataframe()\n        .reset_index()\n    )\n\n\ndef view_marchenko_pastur(eigenvalues: xr.DataArray, *, log: bool = False) -&gt; None:\n    fig, ax = plt.subplots()\n    sns.lineplot(\n        ax=ax,\n        data=eigenvalues,\n        x=\"rank\",\n        y=\"eigenvalue\",\n        estimator=\"mean\",\n        errorbar=\"sd\",\n        err_style=\"band\",\n    )\n    if log:\n        ax.set_xscale(\"log\")\n        ax.set_yscale(\"log\")\n        ax.set_ylim(bottom=1e-2)\n\n    sns.despine(ax=ax, offset=20)\n    fig.show()\n\n\neigenvalues = simulate_marchenko_pastur()\nview_marchenko_pastur(eigenvalues)"
  },
  {
    "objectID": "pages/dealing_with_noise.html#cross-validated-pca",
    "href": "pages/dealing_with_noise.html#cross-validated-pca",
    "title": "Dealing with noisy data",
    "section": "Cross-validated PCA",
    "text": "Cross-validated PCA\nIn a whole-brain calcium-imaging study where mice viewed 2,800 natural images while neural responses were recorded, Stringer et al. (2021) developed cross-validated PCA (CV-PCA) as a method to reliably estimate the covariance structure of the neural responses. Since each image was viewed twice, these repetitions could be used as train/test splits to estimate covariance eigenvalues. Specifically, eigenvectors are computed on a training set of data, and cross-validated eigenvalues are computed by computing the covariance between two independent sets of data:\n\n\\begin{align*}\n    \\text{cov}(X_\\text{train}, X_\\text{train})\n    &= X_\\text{train}^\\top X_\\text{train} / (n - 1)\\\\\n    &= V \\Lambda V^\\top\\\\\n    \\\\\n    \\Lambda_\\text{cross-validated}\n    &= \\text{cov}(X_\\text{train}V, X_\\text{test}V)\\\\\n    &= \\left( X_\\text{train} V \\right) ^\\top \\left( X_\\text{test} V \\right) / (n - 1)\n\\end{align*}\n\nThese cross-validated eigenvalues represent the covariance reliably shared across two presentations of the visual stimulus – which is a quantity we are interested in as neuroscientists: what is the “stable” part of the visual representation of a natural image? Notably, these “eigenvalues” need not be positive: if there is no shared covariance between the two systems at a rank, the expected value of the eigenvalue is 0.\n\nSome geometric intuition\n\n\nA computational recipe\n\n\nA computational recipe for cross-validated PCA\nclass CrossValidatedPCA:\n    def __init__(self) -&gt; None:\n        return\n\n    def __call__(self, /, x: np.ndarray, y: np.ndarray) -&gt; np.ndarray:\n        self.pca = PCA()\n        self.pca.fit(x)\n        x_transformed = self.pca.transform(x)\n        y_transformed = self.pca.transform(y)\n\n        cross_covariance = np.cov(\n            x_transformed,\n            y_transformed,\n            rowvar=False,\n        )\n\n        self.cross_validated_spectrum = np.diag(\n            cross_covariance[:self.pca.n_components_, self.pca.n_components_:]\n        )\n\n\n\n\nAnalyzing neural data\nLet’s apply CV-PCA to our fMRI data to see what it looks like!\n\n\nLoad the dataset\ndata = load_dataset(subject=0, roi=\"general\").load()\n\ndisplay(data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'fMRI betas' (presentation: 1400, neuroid: 15724)&gt;\n-0.2375 -0.4001 -0.7933 0.04382 -0.1157 ... 0.2669 -1.051 -0.179 0.03348 -0.2664\nCoordinates: (3/8)\n    x            (neuroid) uint8 12 12 12 12 12 12 12 ... 71 72 72 72 72 72 72\n    y            (neuroid) uint8 21 22 22 22 22 22 23 ... 34 29 29 30 30 30 31\n    ...           ...\n    rep_id       (presentation) uint8 0 0 0 0 0 0 1 0 0 0 ... 0 0 1 1 1 1 1 1 1\nDimensions without coordinates: presentation, neuroid\nAttributes: (3/7)\n    resolution:     1pt8mm\n    preprocessing:  fithrf_GLMdenoise_RR\n    ...             ...\n    citation:       Allen, E.J., St-Yves, G., Wu, Y. et al. A massive 7T fMRI...xarray.DataArray'fMRI betas'presentation: 1400neuroid: 15724-0.2375 -0.4001 -0.7933 0.04382 ... -1.051 -0.179 0.03348 -0.2664array([[-0.23748732, -0.4000817 , -0.79332644, ...,  0.34429136,\n        -0.8983028 , -1.1036999 ],\n       [ 0.60243624, -1.5812274 , -1.0527056 , ..., -0.63479644,\n        -0.54893786,  0.38300768],\n       [ 0.12001861,  1.5943868 ,  0.11450057, ...,  0.36619487,\n         0.02145388,  0.9037204 ],\n       ...,\n       [ 0.4122271 , -1.9848806 , -1.4696951 , ...,  1.1890962 ,\n         0.10346738, -0.18423374],\n       [-0.32920593,  0.44030157,  0.02951132, ...,  1.1662561 ,\n         1.2881701 ,  0.96182734],\n       [-0.04278437, -0.8031657 , -0.45526204, ..., -0.17902693,\n         0.03348494, -0.26644066]], dtype=float32)Coordinates: (8)x(neuroid)uint812 12 12 12 12 ... 72 72 72 72 72array([12, 12, 12, ..., 72, 72, 72], dtype=uint8)y(neuroid)uint821 22 22 22 22 ... 29 30 30 30 31array([21, 22, 22, ..., 30, 30, 31], dtype=uint8)z(neuroid)uint847 45 46 47 48 ... 46 45 46 49 49array([47, 45, 46, ..., 46, 49, 49], dtype=uint8)stimulus_id(presentation)object'image46002' ... 'image52596'array(['image46002', 'image48617', 'image44980', ..., 'image34186',\n       'image45356', 'image52596'], dtype=object)session_id(presentation)uint80 0 0 0 0 0 0 ... 26 26 26 26 26 26array([ 0,  0,  0, ..., 26, 26, 26], dtype=uint8)trial(presentation)uint160 28 35 44 55 ... 681 684 714 744array([  0,  28,  35, ..., 684, 714, 744], dtype=uint16)run_id(presentation)uint80 0 0 0 0 0 1 ... 9 10 10 10 11 11array([ 0,  0,  0, ..., 10, 11, 11], dtype=uint8)rep_id(presentation)uint80 0 0 0 0 0 1 0 ... 0 1 1 1 1 1 1 1array([0, 0, 0, ..., 1, 1, 1], dtype=uint8)Indexes: (0)Attributes: (7)resolution :1pt8mmpreprocessing :fithrf_GLMdenoise_RRz_score :Trueroi :generalsubject :0brain shape :[ 81 104  83]citation :Allen, E.J., St-Yves, G., Wu, Y. et al. A massive 7T fMRI dataset to bridge cognitive neuroscience and artificial intelligence. Nat Neurosci 25, 116-126 (2022). https://doi.org/10.1038/s41593-021-00962-x\n\n\nNote that the data contain fMRI responses to two repetitions of each image.\n\n\nCompute the cross-validated spectrum\ndata_repetition_1 = data.isel({\"presentation\": data[\"rep_id\"] == 0}).sortby(\n    \"stimulus_id\"\n)\ndata_repetition_2 = data.isel({\"presentation\": data[\"rep_id\"] == 1}).sortby(\n    \"stimulus_id\"\n)\n\ncv_pca = CrossValidatedPCA()\ncv_pca(data_repetition_1.values, data_repetition_2.values)\n\n\n\n\nPlot the raw cross-validated spectrum\ndef plot_cross_validated_spectrum(\n    cv_pca: CrossValidatedPCA,\n    *,\n    log: bool = False,\n    original: bool = False,\n    square: bool = False,\n    bin_logarithmically: bool = False,\n) -&gt; mpl.figure.Figure:\n    fig, ax = plt.subplots()\n\n    data = pd.DataFrame(\n        {\n            \"rank\": 1 + np.arange(len(cv_pca.cross_validated_spectrum) - 1),\n            \"cross-validated\": cv_pca.cross_validated_spectrum[:-1],\n            \"original\": cv_pca.pca.explained_variance_[:-1],\n        }\n    ).melt(\n        id_vars=[\"rank\"],\n        value_vars=[\"cross-validated\", \"original\"],\n        value_name=\"eigenvalue\",\n        var_name=\"spectrum\",\n    )\n\n    if original:\n        sns.lineplot(\n            ax=ax,\n            data=data,\n            x=\"rank\",\n            y=\"eigenvalue\",\n            hue=\"spectrum\",\n        )\n    else:\n        data = (\n            data\n            .loc[data[\"spectrum\"] == \"cross-validated\"]\n            .rename(columns={\"eigenvalue\": \"cross-validated eigenvalue\"})\n            .drop(columns=\"spectrum\")\n        )\n\n        if bin_logarithmically:\n            data[\"rank\"] = assign_logarithmic_bins(data[\"rank\"], points_per_bin=5, min_=1, max_=10_000)\n\n            sns.lineplot(\n                ax=ax,\n                data=data,\n                x=\"rank\",\n                y=\"cross-validated eigenvalue\",\n                marker=\"o\",\n                dashes=False,\n                ls=\"None\",\n                err_style=\"bars\",\n                estimator=\"mean\",\n                errorbar=\"sd\",\n            )\n        else:\n            sns.lineplot(\n                ax=ax,\n                data=data,\n                x=\"rank\",\n                y=\"cross-validated eigenvalue\",\n            )\n\n    if log:\n        ax.axhline(0, ls=\"--\", c=\"gray\")\n        ax.set_xlim(left=1)\n        ax.set_ylim(bottom=1e-2)\n        ax.set_xscale(\"log\")\n        ax.set_yscale(\"log\")\n\n        if square:\n            ax.axis(\"square\")\n\n    sns.despine(ax=ax)\n    plt.close(fig)\n\n    return fig\n\n\nplot_cross_validated_spectrum(cv_pca)\n\n\n\n\n\n\n\n\n\n\n\nPlot the cross-validated spectrum on a log-log scale\nplot_cross_validated_spectrum(cv_pca, log=True)\n\n\n\n\n\n\n\n\n\n\n\nPlot both the original and the cross-validated spectrum\nplot_cross_validated_spectrum(cv_pca, log=True, original=True)\n\n\n\n\n\n\n\n\n\n\n\nBin the cross-validated spectrum\nwith sns.axes_style(\"whitegrid\"):\n    fig = plot_cross_validated_spectrum(cv_pca, log=True, bin_logarithmically=True, square=True)\n    ax = fig.get_axes()[0]\n    ax.grid(True, which=\"minor\", c=\"whitesmoke\")\n    ax.grid(True, which=\"major\", c=\"lightgray\")\n    for loc in (\"left\", \"bottom\"):\n        ax.spines[loc].set_visible(False)\n    display(fig)"
  },
  {
    "objectID": "pages/dealing_with_noise.html#power-law-exponent-of--1",
    "href": "pages/dealing_with_noise.html#power-law-exponent-of--1",
    "title": "Dealing with noisy data",
    "section": "Power-law exponent of -1",
    "text": "Power-law exponent of -1\nInterestingly, the power-law exponent of the neural data appears very close to -1. In fact, a power-law exponent of -1 appears with surprising regularity both in neuroscience and other fields, indicating a system at a critical point.\nTODO:\n\nSame amount of variance at each decade - each decade is equally important (if assessed using variance)\nWhat does this tell us about neural coding?\nShow the Stringer result as comparison, zebrafish?\nInformation coding (Visual system operating at a critical threshold - scale-free dimensionality, more data -&gt; extend even further\n\n\n\n\n\n\n\nAn open question: is the power-law exponent of -1 universal?\n\n\n\nOpen question: same power law everywhere? Sensory systems vs cognitive systems? Different representational formats, LD?\nCheck your data!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A High-Dimensional View of Neuroscience",
    "section": "",
    "text": "This site contains material for a tutorial presented at the conference on Cognitive Computational Neuroscience 2023.\n\n\n\n\n\n\nDon’t miss the tutorial!\n\n\n\n\nWhere\n\nEast Schools\n\nWhen\n\nSaturday, August 26, 2023 @ 10:45 - 12:30\n\n\n\n\n\n\n\n\n\n\nRun the tutorial interactively – or just follow along!\n\n\n\nEach section is a computational notebook that can be run on Google Colab – just follow the links below! If you can’t run the notebooks, just follow along on the website!\n\n\n\n\n\nSection\nRead\nInteract\nDownload\n\n\n\n\nAn introduction to PCA\nwebsite\nColab\ndownload\n\n\nExploring a neural dataset\nwebsite\nColab\ndownload\n\n\nDealing with noisy data\nwebsite\nColab\ndownload\n\n\nComparing high-dimensional representations\nwebsite\nColab\ndownload\n\n\nDeep neural networks\nwebsite\nColab\ndownload\n\n\n\n\n\n\n\n\n\nIf you’d prefer to run the notebooks locally…\n\n\n\n\n\nCreate a Python virtual environment with Python &gt;=3.10.12 to run the notebooks. The required dependencies will be automatically installed when you run the first cell of each notebook.\n\n\n\n\n\n\n\n\n\nNotice a typo? Have any feedback?\n\n\n\nUse the Report an issue button on the sidebar of each page to contact us! Feel free to suggest edits by using the Edit this page button too!"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "A High-Dimensional View of Neuroscience",
    "section": "",
    "text": "This site contains material for a tutorial presented at the conference on Cognitive Computational Neuroscience 2023.\n\n\n\n\n\n\nDon’t miss the tutorial!\n\n\n\n\nWhere\n\nEast Schools\n\nWhen\n\nSaturday, August 26, 2023 @ 10:45 - 12:30\n\n\n\n\n\n\n\n\n\n\nRun the tutorial interactively – or just follow along!\n\n\n\nEach section is a computational notebook that can be run on Google Colab – just follow the links below! If you can’t run the notebooks, just follow along on the website!\n\n\n\n\n\nSection\nRead\nInteract\nDownload\n\n\n\n\nAn introduction to PCA\nwebsite\nColab\ndownload\n\n\nExploring a neural dataset\nwebsite\nColab\ndownload\n\n\nDealing with noisy data\nwebsite\nColab\ndownload\n\n\nComparing high-dimensional representations\nwebsite\nColab\ndownload\n\n\nDeep neural networks\nwebsite\nColab\ndownload\n\n\n\n\n\n\n\n\n\nIf you’d prefer to run the notebooks locally…\n\n\n\n\n\nCreate a Python virtual environment with Python &gt;=3.10.12 to run the notebooks. The required dependencies will be automatically installed when you run the first cell of each notebook.\n\n\n\n\n\n\n\n\n\nNotice a typo? Have any feedback?\n\n\n\nUse the Report an issue button on the sidebar of each page to contact us! Feel free to suggest edits by using the Edit this page button too!"
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "A High-Dimensional View of Neuroscience",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nThanks to the Natural Scene Dataset team for permission to use it for this tutorial and to the Open Science Foundation for hosting the data files!"
  },
  {
    "objectID": "pages/comparing_representations.html",
    "href": "pages/comparing_representations.html",
    "title": "Comparing high-dimensional representations",
    "section": "",
    "text": "Run this notebook interactively!\n\n\n\nHere’s a link to this notebook on Google Colab."
  },
  {
    "objectID": "pages/comparing_representations.html#pls-svd",
    "href": "pages/comparing_representations.html#pls-svd",
    "title": "Comparing high-dimensional representations",
    "section": "PLS-SVD",
    "text": "PLS-SVD\nJust as PCA identifies the principal directions of variance of a system, PLS-SVD identifies the principal directions of shared variance between two systems. Specifically, just as PCA computes the eigendecomposition of the auto-covariance, PLS-SVD computes the singular value decomposition of the cross-covariance:\nX^\\top Y = U \\Sigma V^\\top.\nHere, the left singular vectors U define a rotation of the system X into some latent space, the right singular vectors V define a rotation of system Y into the same latent space, and the singular values \\Sigma\n\n\n\n\n\n\nWhat happens when X = Y?\n\n\n\nNote that if X = Y, PLS-SVD reduces to PCA:\n\n\n\n\nInstall all required dependencies\n# TODO uncomment before final packaging\n# %pip install git+https://github.com/BonnerLab/ccn-tutorial.git\n\n\n\n\nImport various libraries\nfrom collections.abc import Sequence\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nimport torch\nfrom sklearn.decomposition import TruncatedSVD\nimport seaborn as sns\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\nfrom IPython.display import display\n\nfrom utilities.brain import (\n    load_dataset,\n    average_data_across_repetitions,\n    load_stimuli,\n    plot_brain_map,\n)\nfrom utilities.computation import svd\n\n\n\n\nSet some visualization defaults\n%matplotlib inline\n\nsns.set_theme(\n    context=\"notebook\",\n    style=\"white\",\n    palette=\"deep\",\n    rc={\"legend.edgecolor\": \"None\"},\n)\nset_matplotlib_formats(\"svg\")\n\npd.set_option(\"display.max_rows\", 5)\npd.set_option(\"display.max_columns\", 10)\npd.set_option(\"display.precision\", 3)\npd.set_option(\"display.show_dimensions\", False)\n\nxr.set_options(display_max_rows=3, display_expand_data=False)\n\nwarnings.filterwarnings(\"ignore\")\n\n\n\n\nInitialize a deterministic random number generator\nrandom_state = 0\nrng = np.random.default_rng(seed=random_state)\n\n\n\n\nA computational recipe for PLS-SVD\nclass PLSSVD:\n    def __init__(self) -&gt; None:\n        self.left_mean: np.ndarray\n        self.right_mean: np.ndarray\n        self.left_singular_vectors: np.ndarray\n        self.right_singular_vectors: np.ndarray\n\n    def fit(self, /, x: np.ndarray, y: np.ndarray) -&gt; None:\n1        self.left_mean = x.mean(axis=-2)\n        self.right_mean = y.mean(axis=-2)\n\n        x_centered = x - self.left_mean\n        y_centered = y - self.right_mean\n\n        n_stimuli = x.shape[-2]\n\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        cross_covariance = (np.swapaxes(x_centered, -1, -2) @ y_centered) / (\n            n_stimuli - 1\n2        )\n\n        (\n            self.left_singular_vectors,\n            self.singular_values,\n            self.right_singular_vectors,\n        ) = svd(\n            torch.from_numpy(cross_covariance).to(device),\n            n_components=min([*x.shape, *y.shape]),\n            truncated=True,\n            seed=random_state,\n3        )\n\n        n_stimuli = data.shape[-2]\n\n        self.left_singular_vectors = self.left_singular_vectors.cpu().numpy()\n        self.singular_values = self.singular_values.cpu().numpy()\n        self.right_singular_vectors = self.right_singular_vectors.cpu().numpy()\n\n    def transform(self, /, z: np.ndarray, *, direction: str) -&gt; np.ndarray:\n        match direction:\n            case \"left\":\n4                return (z - self.left_mean) @ self.left_singular_vectors\n            case \"right\":\n                return (z - self.right_mean) @ self.right_singular_vectors\n            case _:\n                raise ValueError(\"direction must be 'left' or 'right'\")\n\n\n\n1\n\nCenter the data matrices X and Y.\n\n2\n\nCompute their cross-covariance X^\\top Y / (n - 1).\n\n3\n\nCompute the singular value decomposition of the cross-covariance.\n\n4\n\nTo project data from the ambient space (X or Y) to the latent space, we must subtract the mean computed in Step 1, and multiply the data by the corresponding singular vectors."
  },
  {
    "objectID": "pages/comparing_representations.html#comparing-brains",
    "href": "pages/comparing_representations.html#comparing-brains",
    "title": "Comparing high-dimensional representations",
    "section": "Comparing brains",
    "text": "Comparing brains\nIn the same way that we can PLS-SVD to estimate the shared variance across presentations of the same stimuli within a participant, we can also use it to estimate the shared variance in the neural representations of the same stimuli across participants.\nWe have two data matrices X \\in \\mathbb{R}^{N \\times P_X} and Y \\in \\mathbb{R}^{N \\times P_Y} from two participants. We could directly compute the singular values of their cross-covariance, which would be a direct estimate of the shared variance between these two representations.\nHowever, we run into the same issue as before: the singular values of a matrix are always positive and we won’t be able to use the magnitude of the singular value to assess the reliability of the variance along that dimension.\nInstead, we can use a cross-validated approach similar to CV-PCA, except that instead of testing generalization across different presentations of the stimuli, we can evaluate the reliable shared variance between the two representations across stimuli.\nSpecifically, we can divide the images into two: a training split and a test split. We can compute singular vectors on the training split, and evalute test singular values on the test split, analogous to the CV-PCA procedure:\n\n\\begin{align*}\n    \\text{cov}(X_\\text{train}, Y_\\text{train})\n    &= X_\\text{train}^\\top Y_\\text{train} / (n - 1)\\\\\n    &= U \\Sigma V^\\top\\\\\n    \\\\\n    \\Sigma_\\text{cross-validated}\n    &= \\text{cov}(X_\\text{train} U, Y_\\text{test} V)\\\\\n    &= \\left( X_\\text{train} U \\right) ^\\top \\left( Y_\\text{test} V \\right) / (n - 1)\n\\end{align*}"
  },
  {
    "objectID": "pages/comparing_representations.html#comparing-brains-and-dnns",
    "href": "pages/comparing_representations.html#comparing-brains-and-dnns",
    "title": "Comparing high-dimensional representations",
    "section": "Comparing brains and DNNs",
    "text": "Comparing brains and DNNs\n\n\nLoad the datasets\n# subject_1 = average_data_across_repetitions(load_dataset(subject=0, roi=\"general\"))\n# subject_2 = average_data_across_repetitions(load_dataset(subject=1, roi=\"general\"))\n# subject_1 = subject_1.sortby(\"stimulus_id\")\n# subject_2 = subject_2.sortby(\"stimulus_id\")\n\n# display(subject_1)\n# display(subject_2)\n\n# plssvd = PLSSVD()\n# plssvd.fit(\n#     data_repetition_1.values,\n#     data_repetition_1.values,\n# )\n# rep_1_transformed = plssvd.transform(data_repetition_1.values, direction=\"left\")\n# rep_2_transformed = plssvd.transform(data_repetition_2.values, direction=\"right\")\n\n\n# n_neurons_1 = rep_1_transformed.shape[-1]\n# cv_spectrum = np.diag(\n#     np.cov(rep_1_transformed, rep_2_transformed, rowvar=False)[\n#         :n_neurons_1, n_neurons_1:\n#     ]\n# )\n# cv_spectrum = pd.DataFrame(\n#     cv_spectrum, columns=[\"cross-validated singular value\"]\n# ).assign(rank=np.arange(len(cv_spectrum)) + 1)\n# cv_spectrum = cv_spectrum.assign(\n#     bin=bin_logarithmically(\n#         cv_spectrum[\"cross-validated singular value\"],\n#         points_per_bin=5,\n#         min_=1,\n#         max_=10_000,\n#     )\n# )\n\n# fig, ax = plt.subplots()\n# sns.lineplot(ax=ax, data=cv_spectrum, x=\"rank\", y=\"cross-validated singular value\")\n# sns.despine(ax=ax, offset=20)\n\n# fig, ax = plt.subplots()\n# sns.lineplot(ax=ax, data=cv_spectrum, x=\"rank\", y=\"cross-validated singular value\")\n# ax.set_xscale(\"log\")\n# ax.set_yscale(\"log\")\n# ax.set_ylim(bottom=1e-3)\n# sns.despine(ax=ax, offset=20)\n\n# fig, ax = plt.subplots()\n# sns.lineplot(\n#     ax=ax,\n#     data=cv_spectrum.groupby(\"bin\").mean().rename(columns={\"bin\": \"rank\"}),\n#     x=\"rank\",\n#     y=\"cross-validated singular value\",\n#     ls=None,\n#     marker=\"o\",\n# )\n# ax.set_xscale(\"log\")\n# ax.set_yscale(\"log\")\n# sns.despine(ax=ax, offset=20)"
  },
  {
    "objectID": "pages/deep_neural_networks.html",
    "href": "pages/deep_neural_networks.html",
    "title": "Deep neural networks",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "pages/introducing_pca.html",
    "href": "pages/introducing_pca.html",
    "title": "An introduction to PCA",
    "section": "",
    "text": "Run this notebook interactively!\n\n\n\nHere’s a link to this notebook on Google Colab."
  },
  {
    "objectID": "pages/introducing_pca.html#a-simple-experiment",
    "href": "pages/introducing_pca.html#a-simple-experiment",
    "title": "An introduction to PCA",
    "section": "A simple experiment",
    "text": "A simple experiment\nLet’s perform an imaginary neuroscience experiment! We’ll record voltages from P = 2 neurons in visual cortex while the participant passively views N = 1000 dots of different colors and sizes.\n\n\nInstall all required dependencies\n# TODO uncomment before final packaging\n# %pip install git+https://github.com/BonnerLab/ccn-tutorial.git\n\n\n\n\nImport various libraries\nfrom collections.abc import Sequence, Callable\nimport warnings\nfrom typing import NamedTuple\n\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nimport seaborn as sns\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML\n\n\n\n\nSet some visualization defaults\n%matplotlib inline\n\nsns.set_theme(\n    context=\"notebook\",\n    style=\"white\",\n    palette=\"deep\",\n    rc={\"legend.edgecolor\": \"None\"},\n)\nset_matplotlib_formats(\"svg\")\n\npd.set_option(\"display.max_rows\", 5)\npd.set_option(\"display.max_columns\", 10)\npd.set_option(\"display.precision\", 3)\npd.set_option(\"display.show_dimensions\", False)\n\nxr.set_options(display_max_rows=3, display_expand_data=False)\n\nwarnings.filterwarnings(\"ignore\")\n\n\n\n\nInitialize a deterministic random number generator\nrandom_state = 0\nrng = np.random.default_rng(seed=random_state)\n\n\n\nCreating the stimuli\nLet’s create N = 1000 dots of different colors and sizes. From the scatterplot, we can see that the two latent variables are uncorrelated.\n\n\nCreate stimulus dots of various colors and sizes\ndef create_stimuli(\n    *,\n    n_stimuli: int,\n    rng: np.random.Generator,\n) -&gt; pd.DataFrame:\n    return pd.DataFrame(\n        {\n            \"color\": rng.random(size=(n_stimuli,)),\n            \"size\": rng.random(size=(n_stimuli,)),\n        }\n    ).set_index(1 + np.arange(n_stimuli))\n\n\ndef view_stimuli(data: pd.DataFrame) -&gt; mpl.figure.Figure:\n    fig, ax = plt.subplots()\n    sns.scatterplot(\n        ax=ax,\n        data=data,\n        x=\"color\",\n        y=\"size\",\n        hue=\"color\",\n        size=\"size\",\n        palette=\"flare\",\n        legend=False,\n    )\n    sns.despine(ax=ax, trim=True)\n    fig.tight_layout()\n    plt.close(fig)\n\n    return fig\n\n\nstimuli = create_stimuli(n_stimuli=1_000, rng=rng)\n\nview_stimuli(stimuli)\n\n\n\n\n\n\n\n\n\n\n\nSimulating neural responses\nNow, let’s simulate some neural data. We need to decide how the P = 2 neurons might respond to these N = 1000 stimulus dots. Each neuron could respond to either one or both of the latent features that define these stimuli – \\text{color} and \\text{size}. The neuron’s responses could also be subject to noise. Hence, we model each neuron’s response r_\\text{neuron} as a simple linear combination of the two latent features with stimulus-independent Gaussian noise \\epsilon:\nr_{\\text{neuron}} \\sim \\beta_{\\text{color}} \\left( \\text{color} \\right) + \\beta_{\\text{size}} \\left( \\text{size} \\right) + \\epsilon, where \\epsilon \\sim \\mathcal{N}(\\mu_{\\text{neuron}}, \\sigma_{\\text{neuron}}^2)\n\n\nDefine the parameters controlling neuron responses\nNeuron = NamedTuple(\n    \"Neuron\",\n    beta_color=float,\n    beta_size=float,\n    mean=float,\n    std=float,\n)\n\n\n\n\nSimulate neuron responses\ndef simulate_neuron_responses(\n    stimuli: pd.DataFrame,\n    neuron: Neuron,\n    *,\n    rng: np.random.Generator,\n) -&gt; np.ndarray:\n    def z_score(x: np.ndarray) -&gt; np.ndarray:\n        return (x - x.mean()) / x.std()\n\n    return (\n        neuron.beta_color * z_score(stimuli[\"color\"])\n        + neuron.beta_size * z_score(stimuli[\"size\"])\n        + neuron.std * rng.standard_normal(size=(len(stimuli),))\n        + neuron.mean\n    )\n\n\n\n\nSimulate multiple neurons’ responses\ndef simulate_multiple_neuron_responses(\n    *,\n    stimuli: pd.DataFrame,\n    neurons: Sequence[Neuron],\n    rng: np.random.Generator,\n) -&gt; xr.DataArray:\n    data = []\n    for i_neuron, neuron in enumerate(neurons):\n        data.append(\n            xr.DataArray(\n                data=simulate_neuron_responses(\n                    stimuli=stimuli,\n                    neuron=neuron,\n                    rng=rng,\n                ),\n                dims=(\"stimulus\",),\n                coords={\n                    column: (\"stimulus\", values)\n                    for column, values in stimuli.reset_index(names=\"stimulus\").items()\n                },\n            )\n            .expand_dims({\"neuron\": [i_neuron + 1]})\n            .assign_coords(\n                {\n                    field: (\"neuron\", [float(value)])\n                    for field, value in neuron._asdict().items()\n                }\n            )\n        )\n\n    return (\n        xr.concat(data, dim=\"neuron\")\n        .rename(\"neuron responses\")\n        .transpose(\"stimulus\", \"neuron\")\n    )\n\n\nThis procedure produces a data matrix X \\in \\mathbb{R}^{N \\times P} containing the P = 2 neurons’ responses to the N = 1000 stimuli.\n\n\nSimulate the responses of two neurons to the stimuli\nneurons = (\n    Neuron(beta_color=3, beta_size=-2, std=1, mean=7),\n    Neuron(beta_color=-2, beta_size=5, std=3, mean=-6),\n)\n\ndata = simulate_multiple_neuron_responses(\n    stimuli=stimuli,\n    neurons=neurons,\n    rng=rng,\n)\n\ndisplay(data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'neuron responses' (stimulus: 1000, neuron: 2)&gt;\n12.97 -15.39 1.005 3.224 1.226 2.431 ... 6.028 -6.32 5.488 -16.32 6.215 -9.989\nCoordinates: (3/8)\n  * neuron      (neuron) int64 1 2\n  * stimulus    (stimulus) int64 1 2 3 4 5 6 7 ... 994 995 996 997 998 999 1000\n    ...          ...\n    std         (neuron) float64 1.0 3.0xarray.DataArray'neuron responses'stimulus: 1000neuron: 212.97 -15.39 1.005 3.224 1.226 ... -6.32 5.488 -16.32 6.215 -9.989array([[ 12.96533678, -15.38921968],\n       [  1.00523852,   3.22448895],\n       [  1.2258057 ,   2.43055775],\n       ...,\n       [  6.02810356,  -6.32031526],\n       [  5.48782478, -16.32351293],\n       [  6.21490603,  -9.98853112]])Coordinates: (8)neuron(neuron)int641 2array([1, 2])stimulus(stimulus)int641 2 3 4 5 ... 996 997 998 999 1000array([   1,    2,    3, ...,  998,  999, 1000])color(stimulus)float640.637 0.2698 ... 0.1649 0.38array([6.36961687e-01, 2.69786714e-01, 4.09735239e-02, 1.65276355e-02,\n       8.13270239e-01, 9.12755577e-01, 6.06635776e-01, 7.29496561e-01,\n       5.43624991e-01, 9.35072424e-01, 8.15853554e-01, 2.73850017e-03,\n       8.57404277e-01, 3.35855753e-02, 7.29655446e-01, 1.75655621e-01,\n       8.63178922e-01, 5.41461220e-01, 2.99711891e-01, 4.22687221e-01,\n       2.83196711e-02, 1.24283276e-01, 6.70624415e-01, 6.47189512e-01,\n       6.15385111e-01, 3.83677554e-01, 9.97209936e-01, 9.80835339e-01,\n       6.85541984e-01, 6.50459276e-01, 6.88446731e-01, 3.88921424e-01,\n       1.35096505e-01, 7.21488340e-01, 5.25354322e-01, 3.10241876e-01,\n       4.85835359e-01, 8.89487834e-01, 9.34043516e-01, 3.57795197e-01,\n       5.71529831e-01, 3.21869391e-01, 5.94300030e-01, 3.37911226e-01,\n       3.91619001e-01, 8.90274352e-01, 2.27157594e-01, 6.23187145e-01,\n       8.40153436e-02, 8.32644148e-01, 7.87098307e-01, 2.39369443e-01,\n       8.76484231e-01, 5.85680348e-02, 3.36117061e-01, 1.50279467e-01,\n       4.50339367e-01, 7.96324270e-01, 2.30642209e-01, 5.20213011e-02,\n       4.04551840e-01, 1.98513045e-01, 9.07530456e-02, 5.80332386e-01,\n       2.98696133e-01, 6.71994878e-01, 1.99515444e-01, 9.42113111e-01,\n       3.65110168e-01, 1.05495280e-01, 6.29108152e-01, 9.27154553e-01,\n       4.40377155e-01, 9.54590494e-01, 4.99895814e-01, 4.25228625e-01,\n       6.20213452e-01, 9.95096505e-01, 9.48943675e-01, 4.60045139e-01,\n...\n       3.39811155e-01, 2.21699710e-04, 4.82537622e-01, 6.08000665e-01,\n       9.29904601e-02, 2.42094402e-01, 8.03991821e-01, 8.40281560e-01,\n       3.87733254e-01, 8.14223731e-01, 2.77140253e-01, 7.06108222e-01,\n       5.45456624e-01, 4.40099079e-01, 6.56442276e-01, 1.33906791e-02,\n       1.62443443e-01, 2.93823464e-01, 6.80562610e-01, 7.06235313e-01,\n       6.80760824e-01, 7.67617107e-01, 7.95515610e-02, 1.05888908e-01,\n       8.55351160e-01, 3.56837753e-01, 5.68371290e-01, 5.03502806e-01,\n       6.26662571e-01, 7.69467112e-02, 7.69790226e-01, 1.23402328e-01,\n       6.81374462e-01, 4.02142099e-01, 4.92261636e-01, 6.71693734e-01,\n       3.71002751e-01, 4.60374714e-02, 9.64211552e-01, 5.22676899e-01,\n       7.42144641e-01, 5.31294834e-01, 8.19686903e-01, 5.64616179e-01,\n       1.22756878e-01, 6.41906565e-01, 1.72740669e-01, 8.23654135e-01,\n       6.81061600e-01, 9.39808638e-01, 6.29080790e-01, 2.25163097e-01,\n       5.57137546e-01, 7.71772277e-01, 7.11888298e-01, 3.42296706e-01,\n       6.55351151e-01, 9.35269061e-01, 6.84810043e-01, 3.67301402e-01,\n       9.10758330e-01, 8.27624193e-01, 8.55183760e-01, 1.06841377e-01,\n       2.90828834e-01, 7.90127803e-01, 2.74807496e-01, 7.37059356e-02,\n       6.83266012e-01, 7.99269956e-01, 6.41767808e-01, 3.44843336e-01,\n       5.59773319e-01, 2.15199514e-02, 5.62661656e-01, 8.56801175e-01,\n       7.80532350e-02, 3.83319397e-01, 1.64863718e-01, 3.80007897e-01])size(stimulus)float640.01301 0.8278 ... 0.08158 0.3216array([0.01300767, 0.82776292, 0.49624331, 0.43591807, 0.60179472,\n       0.8500282 , 0.29126072, 0.26751697, 0.04949421, 0.26639909,\n       0.06621185, 0.04155849, 0.55273056, 0.18383489, 0.07425772,\n       0.91671474, 0.14873389, 0.09483079, 0.97067806, 0.66696696,\n       0.72575404, 0.563204  , 0.07038971, 0.84187724, 0.418029  ,\n       0.39246782, 0.13530924, 0.11321989, 0.52224593, 0.56874359,\n       0.51868554, 0.61312468, 0.87764346, 0.50420484, 0.37914768,\n       0.2565727 , 0.30684664, 0.56080705, 0.79537234, 0.44112103,\n       0.04076233, 0.1881545 , 0.09065223, 0.33334341, 0.68437666,\n       0.59071473, 0.66212759, 0.45459513, 0.10978054, 0.29625596,\n       0.51096048, 0.49716497, 0.24366139, 0.82530156, 0.43331334,\n       0.84545613, 0.26549263, 0.94193959, 0.11185735, 0.76918249,\n       0.02018645, 0.23632066, 0.8705533 , 0.350105  , 0.93247949,\n       0.929417  , 0.80019258, 0.39610545, 0.8582685 , 0.45710434,\n       0.1261722 , 0.85195837, 0.8162467 , 0.13556544, 0.86652652,\n       0.51896305, 0.74359076, 0.26817602, 0.21546148, 0.84831281,\n       0.6002138 , 0.14770547, 0.36587009, 0.85903582, 0.46828358,\n       0.3368529 , 0.34095386, 0.8246442 , 0.45429903, 0.9483535 ,\n       0.31220015, 0.75648033, 0.28570549, 0.7678388 , 0.01759798,\n       0.12982098, 0.25925691, 0.87009196, 0.32249838, 0.48352554,\n...\n       0.25857775, 0.09677339, 0.18039325, 0.25448073, 0.83934999,\n       0.22122572, 0.82839782, 0.74329961, 0.97429452, 0.75359014,\n       0.11511305, 0.94004275, 0.84209462, 0.4436286 , 0.43358894,\n       0.03095428, 0.21764154, 0.71488612, 0.1105268 , 0.99174489,\n       0.02168247, 0.99097346, 0.29620757, 0.46086521, 0.54547145,\n       0.28955319, 0.22049757, 0.0505692 , 0.823433  , 0.97230937,\n       0.12555748, 0.85983084, 0.72053945, 0.75022534, 0.38780546,\n       0.05757491, 0.69042312, 0.96212643, 0.65875825, 0.23405231,\n       0.53673526, 0.12167514, 0.71787855, 0.67286419, 0.446794  ,\n       0.00866449, 0.06036607, 0.68197769, 0.69241334, 0.57520933,\n       0.22769122, 0.66313159, 0.1055052 , 0.62768057, 0.57231791,\n       0.35549364, 0.21916604, 0.7245827 , 0.18099196, 0.15735466,\n       0.63276412, 0.66062453, 0.1019691 , 0.26228831, 0.09859603,\n       0.91383146, 0.00838652, 0.35101158, 0.15682101, 0.46699488,\n       0.90683736, 0.70737638, 0.36017375, 0.1866537 , 0.70501213,\n       0.54191587, 0.72028997, 0.04485529, 0.17314062, 0.3198733 ,\n       0.4665367 , 0.56944602, 0.56209399, 0.54291566, 0.56611634,\n       0.41747562, 0.27881285, 0.51812954, 0.12186051, 0.74927137,\n       0.95293572, 0.05409649, 0.78232714, 0.22383289, 0.33641135,\n       0.03353818, 0.9690858 , 0.56209561, 0.08158143, 0.32155563])beta_color(neuron)float643.0 -2.0array([ 3., -2.])beta_size(neuron)float64-2.0 5.0array([-2.,  5.])mean(neuron)float647.0 -6.0array([ 7., -6.])std(neuron)float641.0 3.0array([1., 3.])Indexes: (2)neuronPandasIndexPandasIndex(Index([1, 2], dtype='int64', name='neuron'))stimulusPandasIndexPandasIndex(Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n       ...\n        991,  992,  993,  994,  995,  996,  997,  998,  999, 1000],\n      dtype='int64', name='stimulus', length=1000))Attributes: (0)\n\n\n\n\nVisualizing the neurons\nWe can visualize the responses of each neuron to each dot. Note that this is a 1-dimensional scatterplot; the spread along the vertical axis is just for visualization purposes.\n\n\nVisualize the individual neuron responses\ndef view_individual_scatter(\n    data: xr.DataArray,\n    *,\n    coord: str,\n    dim: str,\n    template_func: Callable[[int], str]\n) -&gt; mpl.figure.Figure:\n    rng = np.random.default_rng()\n    data_ = data.assign_coords(\n        {\"arbitrary\": (\"stimulus\", rng.random(data.sizes[\"stimulus\"]))}\n    )\n    min_, max_ = data_.min(), data_.max()\n\n    n_features = data.sizes[dim]\n\n    fig, axes = plt.subplots(nrows=n_features, figsize=(7, 2 * n_features))\n\n    for index, ax in zip(data[coord].values, axes.flat):\n        label = template_func(index)\n        sns.scatterplot(\n            ax=ax,\n            data=(\n                data_\n                .isel({dim: data[coord].values == index})\n                .rename(label)\n                .to_dataframe()\n            ),\n            x=label,\n            y=\"arbitrary\",\n            hue=\"color\",\n            size=\"size\",\n            palette=\"flare\",\n            legend=False,\n        )\n        sns.despine(ax=ax, left=True, offset=10)\n\n        ax.set_xlim([min_, max_])\n        ax.get_yaxis().set_visible(False)\n\n    fig.tight_layout(h_pad=3)\n    plt.close(fig)\n\n    return fig\n\n\nview_individual_scatter(\n    data,\n    coord=\"neuron\",\n    dim=\"neuron\",\n    template_func=lambda x: f\"neuron {x} response\",\n)\n\n\n\n\n\n\n\n\n\nWe can see that each neuron is tuned to both color and size. Additionally, note that the neurons’ responses have different variances.\n\n\nCompute the variance of each neuron’s responses\nvariances = data.var(dim=\"stimulus\", ddof=1).round(3).rename(\"neuron variances\")\nfor i_neuron in range(variances.sizes[\"neuron\"]):\n    print(f\"variance of neuron {i_neuron + 1} responses: {variances[i_neuron].values}\")\nprint(f\"total variance: {variances.sum().values}\")\n\n\nvariance of neuron 1 responses: 13.758\nvariance of neuron 2 responses: 38.685\ntotal variance: 52.443"
  },
  {
    "objectID": "pages/introducing_pca.html#understanding-the-neural-code",
    "href": "pages/introducing_pca.html#understanding-the-neural-code",
    "title": "An introduction to PCA",
    "section": "Understanding the neural code",
    "text": "Understanding the neural code\nHow is this information encoded in the population activity? Is there a neuron that is sensitive to color and another that is sensitive to size?\nA common approach to studying the information content of our 2 neurons is Representational Similarity Analysis (RSA)(Kriegeskorte 2008), where the dissimaliry of a neuron’s response is obtained for each pair of stimuli, and represented in a matrix of dissimilarities (RDM). Therefore, RDM indicates the degree to which each pair of stimuli is distinguished by the neuron.\n\nKriegeskorte, Nikolaus. 2008. “Representational Similarity Analysis - Connecting the Branches of Systems Neuroscience.” Frontiers in Systems Neuroscience. https://doi.org/10.3389/neuro.06.004.2008.\nFor instance, if neuron 1 was only senstive to color, we would expect to see a high disimilarity for all pairs of stimuli with different color, regardless of their size.\n\nBut what if the neural responses are more complicated, and we have multiple experimental conditions? Is there another view of the population code that might be more informative?"
  },
  {
    "objectID": "pages/introducing_pca.html#studying-the-latent-dimensions",
    "href": "pages/introducing_pca.html#studying-the-latent-dimensions",
    "title": "An introduction to PCA",
    "section": "Studying the latent dimensions",
    "text": "Studying the latent dimensions\nInstead of directly studying the raw observed neural activity, we can focus on the underlying factors that capture the structure and variance in the data.\n\nSome geometric intuition\nSince we only have P = 2 neurons, we can visualize these data as a scatterplot, which makes their covariance apparent.\n\n\nvisualize the joint response\ndef view_joint_scatter(\n    data: xr.DataArray,\n    *,\n    coord: str,\n    dim: str,\n    template_func: Callable[[int], str],\n    draw_axes: bool = False,\n) -&gt; mpl.figure.Figure:\n    fig, ax = plt.subplots()\n\n    data_ = pd.DataFrame(\n        {coord_: data[coord_].values for coord_ in (\"color\", \"size\")}\n        | {\n            template_func(index): (\n                data.isel({dim: index - 1}).to_dataframe()[coord]\n            )\n            for index in (1, 2)\n        }\n    )\n\n    sns.scatterplot(\n        ax=ax,\n        data=data_,\n        x=template_func(1),\n        y=template_func(2),\n        hue=\"color\",\n        size=\"size\",\n        legend=False,\n        palette=\"flare\",\n    )\n    if draw_axes:\n        ax.axhline(0, c=\"gray\", ls=\"--\")\n        ax.axvline(0, c=\"gray\", ls=\"--\")\n\n    ax.set_aspect(\"equal\", \"box\")\n    sns.despine(ax=ax, offset=20)\n    plt.close(fig)\n\n    return fig\n\nview_joint_scatter(\n        data,\n        coord=\"neuron responses\",\n        dim=\"neuron\",\n        template_func=lambda x: f\"neuron {x} response\",\n    )\n\n\n\n\n\n\n\n\n\nThe animation below shows how we can use this to change the way we view the data.\n\n\nAnimate the PCA transformation\ndef animate_pca_transformation(\n    data: xr.DataArray,\n    *,\n    durations: dict[str, int] = {\n        \"center\": 1_000,\n        \"rotate\": 1_000,\n        \"pause\": 500,\n    },\n    interval: int = 50,\n) -&gt; str:\n    def _compute_2d_rotation_matrix(theta: float) -&gt; np.ndarray:\n        return np.array(\n            [\n                [np.cos(theta), -np.sin(theta)],\n                [np.sin(theta), np.cos(theta)],\n            ]\n        )\n\n    fig = view_joint_scatter(\n        data,\n        coord=\"neuron responses\",\n        dim=\"neuron\",\n        template_func=lambda x: f\"neuron {x} response\",\n        draw_axes= True\n    )\n    ax = fig.get_axes()[0]\n    scatter = ax.get_children()[0]\n    title = fig.suptitle(\"neuron responses\")\n\n    n_frames = {key: value // interval + 1 for key, value in durations.items()}\n\n    x_mean, y_mean = data.mean(\"stimulus\").values\n    delta = np.array([x_mean, y_mean]) / n_frames[\"center\"]\n\n    _, _, v_h = np.linalg.svd(data - data.mean(\"stimulus\"))\n    v = v_h.transpose()\n    theta = np.arccos(v[0, 0])\n    rotation = _compute_2d_rotation_matrix(-theta / n_frames[\"rotate\"])\n\n    transformed = (data - data.mean(\"stimulus\")).values @ v\n\n    radius = max(np.linalg.norm(transformed, axis=-1))\n    limit = max(np.abs(data).max(), np.abs(transformed).max(), radius)\n    ax.set_xlim([-limit, limit])\n    ax.set_ylim([-limit, limit])\n    fig.tight_layout()\n\n    frame_to_retitle_center = 2 * n_frames[\"pause\"]\n    frame_to_start_centering = frame_to_retitle_center + n_frames[\"pause\"]\n    frame_to_stop_centering = frame_to_start_centering + n_frames[\"center\"]\n    frame_to_retitle_rotate = frame_to_stop_centering + n_frames[\"pause\"]\n    frame_to_start_rotating = frame_to_retitle_rotate + n_frames[\"pause\"]\n    frame_to_stop_rotating = frame_to_start_rotating + n_frames[\"rotate\"]\n    frame_to_retitle_transformed = frame_to_stop_rotating + n_frames[\"pause\"]\n    frame_to_end = frame_to_retitle_transformed + 2 * n_frames[\"pause\"]\n\n    def _update(frame: int) -&gt; None:\n        if frame &lt; frame_to_retitle_center:\n            return\n        elif frame == frame_to_retitle_center:\n            title.set_text(\"step 1 of 2: center the data\")\n            ax.set_xlabel(\"\")\n            ax.set_ylabel(\"\")\n        elif frame &lt; frame_to_start_centering:\n            return\n        elif frame &lt;= frame_to_stop_centering:\n            scatter.set_offsets(scatter.get_offsets() - delta)\n        elif frame == frame_to_retitle_rotate:\n            title.set_text(\"step 2 of 2: rotate the data\")\n        elif frame &lt; frame_to_start_rotating:\n            return\n        elif frame &lt;= frame_to_stop_rotating:\n            scatter.set_offsets(scatter.get_offsets().data @ rotation)\n        elif frame &lt; frame_to_retitle_transformed:\n            return\n        elif frame == frame_to_retitle_transformed:\n            title.set_text(\"principal components\")\n            ax.set_xlabel(\"principal component 1\")\n            ax.set_ylabel(\"principal component 2\")\n        elif frame &lt;= frame_to_end:\n            return\n\n    animation = FuncAnimation(\n        fig=fig,\n        func=_update,\n        frames=frame_to_end,\n        interval=interval,\n        repeat=False,\n    )\n    plt.close(fig)\n    return animation.to_html5_video()\n\n\n#display(HTML(animate_pca_transformation(data)))\n\n\n\n\n\n\n\n\nTip\n\n\n\nClick on the animation above to visualize the PCA transformation!\n\n\nAs seen in the animation, we can transform our data to view the directions of maximum variance. These directions are the principal components of our data.\n\n\nThe mathematical definition\nGiven a data matrix X \\in \\mathbb{R}^{N \\times P}, we need to compute the eigendecomposition1 of its auto-covariance2:\n\n\\begin{align*}\n    \\text{cov}(X)\n    &= \\left(\\dfrac{1}{n - 1}\\right) (X - \\overline{X})^\\top (X - \\overline{X})\\\\\n    &= V \\Lambda V^\\top\n\\end{align*}\n\nTo do this, we start by computing the auto-covariance of our data matrix, where X is centered (i.e. X - \\overline{X})\n\n\n\nNext , we compute the the eigendecomposition of the auto-covariance (though the computational steps we take to get there are slightly different, as shown later)\n\n\n\nThe columns of V are eigenvectors that specify the directions of variance while the corresponding diagonal elements of \\Lambda are eigenvalues that specify the amount of variance along the eigenvector3.\nFinally, the original data matrix can be transformed by projecting it onto the eigenvectors: \\widetilde{X} = \\left(X - \\overline{X}\\right) V.\n\n\n\n\n\n\n\n\n\n\nViewing PCA as an optimization\n\n\n\n\n\nPCA can be used to project data into a lower-dimensional space (i.e. p \\le f) in a way that best preserves the geometry of the data. Specifically, computing a PCA decomposition of X yields a matrix V \\in \\mathbb{R}^{f \\times p} such that V = \\argmin_{V \\in \\mathbb{U_{f \\times p}}} \\sum_{i=1}^n \\left|| x_i - VV^\\top x_i \\right||_2, where ||\\cdot||_2 denotes the L_2-norm and \\mathbb{U_{f \\times p}} denotes the set of orthonormal matrices with shape f \\times p.\n\n\n\n\n\nA computational recipe\n\nCenter the data matrix.\nCompute its singular value decomposition4.\nThe right singular vectors V of the data matrix are the eigenvectors of its auto-covariance.\nThe singular values \\Sigma of the data matrix are related to the eigenvalues \\Lambda of its auto-covariance as \\Lambda = \\Sigma^2 / (N - 1)\nTo project data from the ambient space to the latent space, we must subtract the mean computed in Step 1, and multiply the data by the eigenvectors.\n\n\n\nA computational recipe for PCA\nclass PCA:\n    def __init__(self) -&gt; None:\n        self.mean: np.ndarray\n        self.eigenvectors: np.ndarray\n        self.eigenvalues: np.ndarray\n\n    def fit(self, /, data: np.ndarray) -&gt; None:\n        self.mean = data.mean(axis=-2)\n\n        data_centered = data - self.mean\n        _, s, v_t = np.linalg.svd(data_centered)\n\n        n_stimuli = data.shape[-2]\n\n        self.eigenvectors = np.swapaxes(v_t, -1, -2)\n        self.eigenvalues = s**2 / (n_stimuli - 1)\n\n    def transform(self, /, data: np.ndarray) -&gt; np.ndarray:\n        return (data - self.mean) @ self.eigenvectors\n\n\n\n\n\n\n\n\nWhy do we compute PCA this way instead of \\text{eig}(\\text{cov}(X))?\n\n\n\n\n\nTo apply PCA to a data matrix, we might be tempted to use the definition and naively compute its auto-covariance followed by an eigendecomposition. However, when the number of neurons P is large, this approach is memory-intensive and prone to numerical errors.\nInstead, we can use the singular value decomposition (SVD) of X to efficiently compute its PCA transformation. Specifically, X = U \\Sigma V^\\top is a singular value decomposition, where U and V are orthonormal and \\Sigma is diagonal.\nThe auto-covariance matrix reduces to X^\\top X / (n - 1) = V \\left(\\frac{\\Sigma^2}{n - 1} \\right) V^\\top, which is exactly the eigendecomposition required.\nSpecifically, the eigenvalues \\lambda_i of the auto-covariance matrix are related to the singular values \\sigma_i of the data matrix as \\lambda_i = \\sigma_i^2 / (N - 1), while the eigenvectors of the auto-covariance matrix are exactly the right singular vectors V of the data matrix X.\n\n\n\n\n\n\n\n\n\nOnly need the first few PCs?\n\n\n\n\n\nCheck out truncated SVD!"
  },
  {
    "objectID": "pages/introducing_pca.html#transforming-the-dataset",
    "href": "pages/introducing_pca.html#transforming-the-dataset",
    "title": "An introduction to PCA",
    "section": "Transforming the dataset",
    "text": "Transforming the dataset\nLet’s now transform our data into its principal components and analyse it in this space.\n\n\nApply the PCA transformation\ndef compute_pca(data: xr.DataArray) -&gt; xr.Dataset:\n    pca = PCA()\n    pca.fit(data.values)\n\n    data_transformed = pca.transform(data.values)\n\n    return xr.Dataset(\n        data_vars={\n            \"score\": xr.DataArray(\n                data=data_transformed,\n                dims=(\"stimulus\", \"component\"),\n            ),\n            \"eigenvector\": xr.DataArray(\n                data=pca.eigenvectors,\n                dims=(\"component\", \"neuron\"),\n            ),\n        },\n        coords={\n            \"rank\": (\"component\", 1 + np.arange(data_transformed.shape[-1])),\n            \"eigenvalue\": (\"component\", pca.eigenvalues),\n        }\n        | {coord: (data[coord].dims[0], data[coord].values) for coord in data.coords},\n    )\n\n\npca = compute_pca(data)\ndisplay(pca[\"score\"])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'score' (stimulus: 1000, component: 2)&gt;\n11.19 1.269 -10.77 -1.394 -9.962 -1.541 ... -1.028 8.777 -5.869 3.39 -2.457\nCoordinates: (3/5)\n  * stimulus    (stimulus) int64 1 2 3 4 5 6 7 ... 994 995 996 997 998 999 1000\n    rank        (component) int64 1 2\n    ...          ...\n    size        (stimulus) float64 0.01301 0.8278 0.4962 ... 0.08158 0.3216\nDimensions without coordinates: componentxarray.DataArray'score'stimulus: 1000component: 211.19 1.269 -10.77 -1.394 -9.962 ... -1.028 8.777 -5.869 3.39 -2.457array([[ 1.11911792e+01,  1.26889981e+00],\n       [-1.07729551e+01, -1.39397546e+00],\n       [-9.96219137e+00, -1.54107707e+00],\n       ...,\n       [ 6.58127224e-03, -1.02783716e+00],\n       [ 8.77667289e+00, -5.86946476e+00],\n       [ 3.39020249e+00, -2.45675640e+00]])Coordinates: (5)stimulus(stimulus)int641 2 3 4 5 ... 996 997 998 999 1000array([   1,    2,    3, ...,  998,  999, 1000])rank(component)int641 2array([1, 2])eigenvalue(component)float6446.3 6.148array([46.29579973,  6.14792569])color(stimulus)float640.637 0.2698 ... 0.1649 0.38array([6.36961687e-01, 2.69786714e-01, 4.09735239e-02, 1.65276355e-02,\n       8.13270239e-01, 9.12755577e-01, 6.06635776e-01, 7.29496561e-01,\n       5.43624991e-01, 9.35072424e-01, 8.15853554e-01, 2.73850017e-03,\n       8.57404277e-01, 3.35855753e-02, 7.29655446e-01, 1.75655621e-01,\n       8.63178922e-01, 5.41461220e-01, 2.99711891e-01, 4.22687221e-01,\n       2.83196711e-02, 1.24283276e-01, 6.70624415e-01, 6.47189512e-01,\n       6.15385111e-01, 3.83677554e-01, 9.97209936e-01, 9.80835339e-01,\n       6.85541984e-01, 6.50459276e-01, 6.88446731e-01, 3.88921424e-01,\n       1.35096505e-01, 7.21488340e-01, 5.25354322e-01, 3.10241876e-01,\n       4.85835359e-01, 8.89487834e-01, 9.34043516e-01, 3.57795197e-01,\n       5.71529831e-01, 3.21869391e-01, 5.94300030e-01, 3.37911226e-01,\n       3.91619001e-01, 8.90274352e-01, 2.27157594e-01, 6.23187145e-01,\n       8.40153436e-02, 8.32644148e-01, 7.87098307e-01, 2.39369443e-01,\n       8.76484231e-01, 5.85680348e-02, 3.36117061e-01, 1.50279467e-01,\n       4.50339367e-01, 7.96324270e-01, 2.30642209e-01, 5.20213011e-02,\n       4.04551840e-01, 1.98513045e-01, 9.07530456e-02, 5.80332386e-01,\n       2.98696133e-01, 6.71994878e-01, 1.99515444e-01, 9.42113111e-01,\n       3.65110168e-01, 1.05495280e-01, 6.29108152e-01, 9.27154553e-01,\n       4.40377155e-01, 9.54590494e-01, 4.99895814e-01, 4.25228625e-01,\n       6.20213452e-01, 9.95096505e-01, 9.48943675e-01, 4.60045139e-01,\n...\n       3.39811155e-01, 2.21699710e-04, 4.82537622e-01, 6.08000665e-01,\n       9.29904601e-02, 2.42094402e-01, 8.03991821e-01, 8.40281560e-01,\n       3.87733254e-01, 8.14223731e-01, 2.77140253e-01, 7.06108222e-01,\n       5.45456624e-01, 4.40099079e-01, 6.56442276e-01, 1.33906791e-02,\n       1.62443443e-01, 2.93823464e-01, 6.80562610e-01, 7.06235313e-01,\n       6.80760824e-01, 7.67617107e-01, 7.95515610e-02, 1.05888908e-01,\n       8.55351160e-01, 3.56837753e-01, 5.68371290e-01, 5.03502806e-01,\n       6.26662571e-01, 7.69467112e-02, 7.69790226e-01, 1.23402328e-01,\n       6.81374462e-01, 4.02142099e-01, 4.92261636e-01, 6.71693734e-01,\n       3.71002751e-01, 4.60374714e-02, 9.64211552e-01, 5.22676899e-01,\n       7.42144641e-01, 5.31294834e-01, 8.19686903e-01, 5.64616179e-01,\n       1.22756878e-01, 6.41906565e-01, 1.72740669e-01, 8.23654135e-01,\n       6.81061600e-01, 9.39808638e-01, 6.29080790e-01, 2.25163097e-01,\n       5.57137546e-01, 7.71772277e-01, 7.11888298e-01, 3.42296706e-01,\n       6.55351151e-01, 9.35269061e-01, 6.84810043e-01, 3.67301402e-01,\n       9.10758330e-01, 8.27624193e-01, 8.55183760e-01, 1.06841377e-01,\n       2.90828834e-01, 7.90127803e-01, 2.74807496e-01, 7.37059356e-02,\n       6.83266012e-01, 7.99269956e-01, 6.41767808e-01, 3.44843336e-01,\n       5.59773319e-01, 2.15199514e-02, 5.62661656e-01, 8.56801175e-01,\n       7.80532350e-02, 3.83319397e-01, 1.64863718e-01, 3.80007897e-01])size(stimulus)float640.01301 0.8278 ... 0.08158 0.3216array([0.01300767, 0.82776292, 0.49624331, 0.43591807, 0.60179472,\n       0.8500282 , 0.29126072, 0.26751697, 0.04949421, 0.26639909,\n       0.06621185, 0.04155849, 0.55273056, 0.18383489, 0.07425772,\n       0.91671474, 0.14873389, 0.09483079, 0.97067806, 0.66696696,\n       0.72575404, 0.563204  , 0.07038971, 0.84187724, 0.418029  ,\n       0.39246782, 0.13530924, 0.11321989, 0.52224593, 0.56874359,\n       0.51868554, 0.61312468, 0.87764346, 0.50420484, 0.37914768,\n       0.2565727 , 0.30684664, 0.56080705, 0.79537234, 0.44112103,\n       0.04076233, 0.1881545 , 0.09065223, 0.33334341, 0.68437666,\n       0.59071473, 0.66212759, 0.45459513, 0.10978054, 0.29625596,\n       0.51096048, 0.49716497, 0.24366139, 0.82530156, 0.43331334,\n       0.84545613, 0.26549263, 0.94193959, 0.11185735, 0.76918249,\n       0.02018645, 0.23632066, 0.8705533 , 0.350105  , 0.93247949,\n       0.929417  , 0.80019258, 0.39610545, 0.8582685 , 0.45710434,\n       0.1261722 , 0.85195837, 0.8162467 , 0.13556544, 0.86652652,\n       0.51896305, 0.74359076, 0.26817602, 0.21546148, 0.84831281,\n       0.6002138 , 0.14770547, 0.36587009, 0.85903582, 0.46828358,\n       0.3368529 , 0.34095386, 0.8246442 , 0.45429903, 0.9483535 ,\n       0.31220015, 0.75648033, 0.28570549, 0.7678388 , 0.01759798,\n       0.12982098, 0.25925691, 0.87009196, 0.32249838, 0.48352554,\n...\n       0.25857775, 0.09677339, 0.18039325, 0.25448073, 0.83934999,\n       0.22122572, 0.82839782, 0.74329961, 0.97429452, 0.75359014,\n       0.11511305, 0.94004275, 0.84209462, 0.4436286 , 0.43358894,\n       0.03095428, 0.21764154, 0.71488612, 0.1105268 , 0.99174489,\n       0.02168247, 0.99097346, 0.29620757, 0.46086521, 0.54547145,\n       0.28955319, 0.22049757, 0.0505692 , 0.823433  , 0.97230937,\n       0.12555748, 0.85983084, 0.72053945, 0.75022534, 0.38780546,\n       0.05757491, 0.69042312, 0.96212643, 0.65875825, 0.23405231,\n       0.53673526, 0.12167514, 0.71787855, 0.67286419, 0.446794  ,\n       0.00866449, 0.06036607, 0.68197769, 0.69241334, 0.57520933,\n       0.22769122, 0.66313159, 0.1055052 , 0.62768057, 0.57231791,\n       0.35549364, 0.21916604, 0.7245827 , 0.18099196, 0.15735466,\n       0.63276412, 0.66062453, 0.1019691 , 0.26228831, 0.09859603,\n       0.91383146, 0.00838652, 0.35101158, 0.15682101, 0.46699488,\n       0.90683736, 0.70737638, 0.36017375, 0.1866537 , 0.70501213,\n       0.54191587, 0.72028997, 0.04485529, 0.17314062, 0.3198733 ,\n       0.4665367 , 0.56944602, 0.56209399, 0.54291566, 0.56611634,\n       0.41747562, 0.27881285, 0.51812954, 0.12186051, 0.74927137,\n       0.95293572, 0.05409649, 0.78232714, 0.22383289, 0.33641135,\n       0.03353818, 0.9690858 , 0.56209561, 0.08158143, 0.32155563])Indexes: (1)stimulusPandasIndexPandasIndex(Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n       ...\n        991,  992,  993,  994,  995,  996,  997,  998,  999, 1000],\n      dtype='int64', name='stimulus', length=1000))Attributes: (0)\n\n\n\nInspecting the eigenvectors\n\n\nDisplay the eigenvectors\nwith xr.set_options(display_expand_data=True):\n    display(pca[\"eigenvector\"])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'eigenvector' (component: 2, neuron: 2)&gt;\narray([[ 0.43538525,  0.90024423],\n       [-0.90024423,  0.43538525]])\nCoordinates: (3/7)\n  * neuron      (neuron) int64 1 2\n    rank        (component) int64 1 2\n    ...          ...\n    std         (neuron) float64 1.0 3.0\nDimensions without coordinates: componentxarray.DataArray'eigenvector'component: 2neuron: 20.4354 0.9002 -0.9002 0.4354array([[ 0.43538525,  0.90024423],\n       [-0.90024423,  0.43538525]])Coordinates: (7)neuron(neuron)int641 2array([1, 2])rank(component)int641 2array([1, 2])eigenvalue(component)float6446.3 6.148array([46.29579973,  6.14792569])beta_color(neuron)float643.0 -2.0array([ 3., -2.])beta_size(neuron)float64-2.0 5.0array([-2.,  5.])mean(neuron)float647.0 -6.0array([ 7., -6.])std(neuron)float641.0 3.0array([1., 3.])Indexes: (1)neuronPandasIndexPandasIndex(Index([1, 2], dtype='int64', name='neuron'))Attributes: (0)\n\n\n\n\nVisualize the transformed data\nfig = view_joint_scatter(\n    data,\n    coord=\"neuron responses\",\n    dim=\"neuron\",\n    template_func=lambda x: f\"neuron {x} response\",\n)\nax = fig.get_axes()[0]\n# TODO plot eigenvectors on joint scatter\n# ax.plot()\n\n\n\n\nInterpreting the transformed data\nWe can view the data projected onto each of the principal components.\n\n\nVisualize principal component scores\nview_individual_scatter(\n    pca[\"score\"],\n    coord=\"rank\",\n    dim=\"component\",\n    template_func=lambda x: f\"principal component {x}\",\n)\n\n\n\n\n\n\n\n\n\nWe observe that:\n\nthe first principal component is largely driven by the size of the stimulus\nthe second principal component is largely driven by the color of the stimulus\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that these components do not directly correspond to either of the latent variables. Rather, each is a mixture of stimulus-dependent signal and noise.\n\n\n\n\nAnalyzing the covariance statistics\nWe can compute the variance along each eigenvector. The total variance along all eigenvectors is the same as the total variance of the original data.\n\n\nDisplay eigenvalues\neigenvalues = pca[\"eigenvalue\"].round(3)\nfor i_neuron in range(eigenvalues.sizes[\"component\"]):\n    print(\n        f\"variance along eigenvector {i_neuron + 1} (eigenvalue {i_neuron + 1}):\"\n        f\" {eigenvalues[i_neuron].values}\"\n    )\nprint(f\"total variance: {eigenvalues.sum().values}\")\n\n\nvariance along eigenvector 1 (eigenvalue 1): 46.296\nvariance along eigenvector 2 (eigenvalue 2): 6.148\ntotal variance: 52.444\n\n\n\n\nView eigenspectrum\ndef view_eigenspectrum(pca: xr.DataArray) -&gt; mpl.figure.Figure:\n    fig, ax = plt.subplots(figsize=(pca.sizes[\"component\"], 5))\n    sns.lineplot(\n        ax=ax,\n        data=pca[\"component\"].to_dataframe(),\n        x=\"rank\",\n        y=\"eigenvalue\",\n        marker=\"s\",\n    )\n    ax.set_xticks(pca[\"rank\"].values)\n    ax.set_ylim(bottom=0)\n    sns.despine(ax=ax, offset=20)\n    plt.close(fig)\n\n    return fig\n\n\nview_eigenspectrum(pca)"
  },
  {
    "objectID": "pages/introducing_pca.html#quantifying-dimensionality",
    "href": "pages/introducing_pca.html#quantifying-dimensionality",
    "title": "An introduction to PCA",
    "section": "Quantifying dimensionality",
    "text": "Quantifying dimensionality\nIn these data, the dimensionality is clear: there are two latent variables and both are evident in the principal components. However, in real data, we typically record from more than P = 2 neurons, therefore judging the dimensionality becomes tricky. To simulate such a scenario, let’s record from more neurons (say P = 10).\n\n\nSimulate responses from more neurons\ndef _simulate_random_neuron(rng: np.random.Generator) -&gt; Neuron:\n    return Neuron(\n        beta_color=rng.integers(-10, 11),\n        beta_size=rng.integers(-10, 11),\n        std=rng.integers(-10, 11),\n        mean=rng.integers(-10, 11),\n    )\n\nneurons = tuple([_simulate_random_neuron(rng) for _ in range(10)])\n\nbig_data = simulate_multiple_neuron_responses(\n    stimuli=stimuli,\n    neurons=neurons,\n    rng=rng,\n)\n\ndisplay(big_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'neuron responses' (stimulus: 1000, neuron: 10)&gt;\n-1.747 -8.53 -7.006 4.696 8.766 28.16 ... 8.782 0.7017 -2.132 -1.981 -1.87\nCoordinates: (3/8)\n  * neuron      (neuron) int64 1 2 3 4 5 6 7 8 9 10\n  * stimulus    (stimulus) int64 1 2 3 4 5 6 7 ... 994 995 996 997 998 999 1000\n    ...          ...\n    std         (neuron) float64 -5.0 2.0 -3.0 5.0 -10.0 ... -2.0 -4.0 -2.0 -8.0xarray.DataArray'neuron responses'stimulus: 1000neuron: 10-1.747 -8.53 -7.006 4.696 8.766 ... 8.782 0.7017 -2.132 -1.981 -1.87array([[ -1.7468685 ,  -8.52988047,  -7.00619911, ..., -12.08407229,\n         -6.11588709,   5.79962078],\n       [  0.5417999 ,   5.76857817, -14.19056082, ...,  -7.57254665,\n         15.63044955, -12.08460524],\n       [-15.14390287,   7.43798007, -11.87857537, ...,  -5.60388679,\n          1.55649921,  -0.7286054 ],\n       ...,\n       [-11.867323  ,   3.04997894,  -8.19304571, ..., -13.63460347,\n          7.49747562,  10.62648332],\n       [-23.71380179,   4.65415007,  -5.80502762, ...,  -7.50271373,\n        -10.13915485,  -8.14599889],\n       [ -7.25947058,   1.02221347,  -8.99930611, ...,  -2.13177182,\n         -1.98124877,  -1.87010738]])Coordinates: (8)neuron(neuron)int641 2 3 4 5 6 7 8 9 10array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])stimulus(stimulus)int641 2 3 4 5 ... 996 997 998 999 1000array([   1,    2,    3, ...,  998,  999, 1000])color(stimulus)float640.637 0.2698 ... 0.1649 0.38array([6.36961687e-01, 2.69786714e-01, 4.09735239e-02, 1.65276355e-02,\n       8.13270239e-01, 9.12755577e-01, 6.06635776e-01, 7.29496561e-01,\n       5.43624991e-01, 9.35072424e-01, 8.15853554e-01, 2.73850017e-03,\n       8.57404277e-01, 3.35855753e-02, 7.29655446e-01, 1.75655621e-01,\n       8.63178922e-01, 5.41461220e-01, 2.99711891e-01, 4.22687221e-01,\n       2.83196711e-02, 1.24283276e-01, 6.70624415e-01, 6.47189512e-01,\n       6.15385111e-01, 3.83677554e-01, 9.97209936e-01, 9.80835339e-01,\n       6.85541984e-01, 6.50459276e-01, 6.88446731e-01, 3.88921424e-01,\n       1.35096505e-01, 7.21488340e-01, 5.25354322e-01, 3.10241876e-01,\n       4.85835359e-01, 8.89487834e-01, 9.34043516e-01, 3.57795197e-01,\n       5.71529831e-01, 3.21869391e-01, 5.94300030e-01, 3.37911226e-01,\n       3.91619001e-01, 8.90274352e-01, 2.27157594e-01, 6.23187145e-01,\n       8.40153436e-02, 8.32644148e-01, 7.87098307e-01, 2.39369443e-01,\n       8.76484231e-01, 5.85680348e-02, 3.36117061e-01, 1.50279467e-01,\n       4.50339367e-01, 7.96324270e-01, 2.30642209e-01, 5.20213011e-02,\n       4.04551840e-01, 1.98513045e-01, 9.07530456e-02, 5.80332386e-01,\n       2.98696133e-01, 6.71994878e-01, 1.99515444e-01, 9.42113111e-01,\n       3.65110168e-01, 1.05495280e-01, 6.29108152e-01, 9.27154553e-01,\n       4.40377155e-01, 9.54590494e-01, 4.99895814e-01, 4.25228625e-01,\n       6.20213452e-01, 9.95096505e-01, 9.48943675e-01, 4.60045139e-01,\n...\n       3.39811155e-01, 2.21699710e-04, 4.82537622e-01, 6.08000665e-01,\n       9.29904601e-02, 2.42094402e-01, 8.03991821e-01, 8.40281560e-01,\n       3.87733254e-01, 8.14223731e-01, 2.77140253e-01, 7.06108222e-01,\n       5.45456624e-01, 4.40099079e-01, 6.56442276e-01, 1.33906791e-02,\n       1.62443443e-01, 2.93823464e-01, 6.80562610e-01, 7.06235313e-01,\n       6.80760824e-01, 7.67617107e-01, 7.95515610e-02, 1.05888908e-01,\n       8.55351160e-01, 3.56837753e-01, 5.68371290e-01, 5.03502806e-01,\n       6.26662571e-01, 7.69467112e-02, 7.69790226e-01, 1.23402328e-01,\n       6.81374462e-01, 4.02142099e-01, 4.92261636e-01, 6.71693734e-01,\n       3.71002751e-01, 4.60374714e-02, 9.64211552e-01, 5.22676899e-01,\n       7.42144641e-01, 5.31294834e-01, 8.19686903e-01, 5.64616179e-01,\n       1.22756878e-01, 6.41906565e-01, 1.72740669e-01, 8.23654135e-01,\n       6.81061600e-01, 9.39808638e-01, 6.29080790e-01, 2.25163097e-01,\n       5.57137546e-01, 7.71772277e-01, 7.11888298e-01, 3.42296706e-01,\n       6.55351151e-01, 9.35269061e-01, 6.84810043e-01, 3.67301402e-01,\n       9.10758330e-01, 8.27624193e-01, 8.55183760e-01, 1.06841377e-01,\n       2.90828834e-01, 7.90127803e-01, 2.74807496e-01, 7.37059356e-02,\n       6.83266012e-01, 7.99269956e-01, 6.41767808e-01, 3.44843336e-01,\n       5.59773319e-01, 2.15199514e-02, 5.62661656e-01, 8.56801175e-01,\n       7.80532350e-02, 3.83319397e-01, 1.64863718e-01, 3.80007897e-01])size(stimulus)float640.01301 0.8278 ... 0.08158 0.3216array([0.01300767, 0.82776292, 0.49624331, 0.43591807, 0.60179472,\n       0.8500282 , 0.29126072, 0.26751697, 0.04949421, 0.26639909,\n       0.06621185, 0.04155849, 0.55273056, 0.18383489, 0.07425772,\n       0.91671474, 0.14873389, 0.09483079, 0.97067806, 0.66696696,\n       0.72575404, 0.563204  , 0.07038971, 0.84187724, 0.418029  ,\n       0.39246782, 0.13530924, 0.11321989, 0.52224593, 0.56874359,\n       0.51868554, 0.61312468, 0.87764346, 0.50420484, 0.37914768,\n       0.2565727 , 0.30684664, 0.56080705, 0.79537234, 0.44112103,\n       0.04076233, 0.1881545 , 0.09065223, 0.33334341, 0.68437666,\n       0.59071473, 0.66212759, 0.45459513, 0.10978054, 0.29625596,\n       0.51096048, 0.49716497, 0.24366139, 0.82530156, 0.43331334,\n       0.84545613, 0.26549263, 0.94193959, 0.11185735, 0.76918249,\n       0.02018645, 0.23632066, 0.8705533 , 0.350105  , 0.93247949,\n       0.929417  , 0.80019258, 0.39610545, 0.8582685 , 0.45710434,\n       0.1261722 , 0.85195837, 0.8162467 , 0.13556544, 0.86652652,\n       0.51896305, 0.74359076, 0.26817602, 0.21546148, 0.84831281,\n       0.6002138 , 0.14770547, 0.36587009, 0.85903582, 0.46828358,\n       0.3368529 , 0.34095386, 0.8246442 , 0.45429903, 0.9483535 ,\n       0.31220015, 0.75648033, 0.28570549, 0.7678388 , 0.01759798,\n       0.12982098, 0.25925691, 0.87009196, 0.32249838, 0.48352554,\n...\n       0.25857775, 0.09677339, 0.18039325, 0.25448073, 0.83934999,\n       0.22122572, 0.82839782, 0.74329961, 0.97429452, 0.75359014,\n       0.11511305, 0.94004275, 0.84209462, 0.4436286 , 0.43358894,\n       0.03095428, 0.21764154, 0.71488612, 0.1105268 , 0.99174489,\n       0.02168247, 0.99097346, 0.29620757, 0.46086521, 0.54547145,\n       0.28955319, 0.22049757, 0.0505692 , 0.823433  , 0.97230937,\n       0.12555748, 0.85983084, 0.72053945, 0.75022534, 0.38780546,\n       0.05757491, 0.69042312, 0.96212643, 0.65875825, 0.23405231,\n       0.53673526, 0.12167514, 0.71787855, 0.67286419, 0.446794  ,\n       0.00866449, 0.06036607, 0.68197769, 0.69241334, 0.57520933,\n       0.22769122, 0.66313159, 0.1055052 , 0.62768057, 0.57231791,\n       0.35549364, 0.21916604, 0.7245827 , 0.18099196, 0.15735466,\n       0.63276412, 0.66062453, 0.1019691 , 0.26228831, 0.09859603,\n       0.91383146, 0.00838652, 0.35101158, 0.15682101, 0.46699488,\n       0.90683736, 0.70737638, 0.36017375, 0.1866537 , 0.70501213,\n       0.54191587, 0.72028997, 0.04485529, 0.17314062, 0.3198733 ,\n       0.4665367 , 0.56944602, 0.56209399, 0.54291566, 0.56611634,\n       0.41747562, 0.27881285, 0.51812954, 0.12186051, 0.74927137,\n       0.95293572, 0.05409649, 0.78232714, 0.22383289, 0.33641135,\n       0.03353818, 0.9690858 , 0.56209561, 0.08158143, 0.32155563])beta_color(neuron)float6410.0 -4.0 1.0 7.0 ... -4.0 0.0 10.0array([10., -4.,  1.,  7., 10., 10., -9., -4.,  0., 10.])beta_size(neuron)float647.0 1.0 -3.0 6.0 ... -3.0 8.0 6.0array([ 7.,  1., -3.,  6.,  1., -7.,  4., -3.,  8.,  6.])mean(neuron)float640.0 -1.0 -9.0 2.0 ... -9.0 3.0 8.0array([ 0., -1., -9.,  2.,  1.,  7., -1., -9.,  3.,  8.])std(neuron)float64-5.0 2.0 -3.0 ... -4.0 -2.0 -8.0array([ -5.,   2.,  -3.,   5., -10.,  -4.,  -2.,  -4.,  -2.,  -8.])Indexes: (2)neuronPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype='int64', name='neuron'))stimulusPandasIndexPandasIndex(Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n       ...\n        991,  992,  993,  994,  995,  996,  997,  998,  999, 1000],\n      dtype='int64', name='stimulus', length=1000))Attributes: (0)\n\n\nAs before, we can visualize each components and plot the eigenspectrum:\n\n\nVisualize principal component scores\nbig_pca = compute_pca(big_data)\n\nview_individual_scatter(\n    big_pca[\"score\"],\n    coord=\"rank\",\n    dim=\"component\",\n    template_func=lambda x: f\"principal component {x}\",\n)\n\n\n\n\n\n\n\n\n\nWe can plot the eigenvalues as a function of rank to visualize the eigenspectrum. The eigensceptrum provides valuable insights about the latent dimensionality of the data.\n\n\nView eigenspectrum\nview_eigenspectrum(big_pca)\n\n\n\n\n\n\n\n\n\nSince we know that this data was generated from exactly 2 latent variables – color and size – we know that the latent dimensionality of the data must be 2. Eyeballing the spectrum, we can corroborate this: the first two dimensions have much higher variance than the rest. We refer to these as the effective dimensions.\nHowever, in real datasets with naturalistic stimuli, we often don’t know what the latent variables are! Based on the spectrum, several approaches are used to quantify the latent dimensionality of a dataset:\n\nRank of the covariance matrix\nThe rank of the covariance matrix – equal to the number of nonzero eigenvalues – would be the latent dimensionality in the ideal setting where the data has zero noise. In real data, the rank is typically equal to the ambient dimensionality, since there is typically some variance along every dimension.\n\n\nSet a threshold of zero on the variance\nprint(f\"rank = {(big_pca.eigenvalue &gt; 0).sum().values}\")\n\ndef view_thresholded_eigenspectrum(pca: PCA, *, threshold: int | float):\n    fig = view_eigenspectrum(pca)\n    ax = fig.get_axes()[0]\n\n    ax.axhline(threshold, ls=\"--\", c=\"gray\")\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    ax.fill_between(x=xlim, y1=ylim[-1], y2=threshold, color=\"green\", alpha=0.1)\n    ax.fill_between(x=xlim, y1=ylim[0], y2=threshold, color=\"red\", alpha=0.1)\n\n    return fig\n\n\nview_thresholded_eigenspectrum(big_pca, threshold=0)\n\n\nrank = 10\n\n\n\n\n\n\n\nSetting an arbitrary variance threshold\nThough not typically used today, another approach is to set an arbitrary threshold on the variance (historically recommended as 1 for normalized data); only dimensions with variance above that threshold are considered useful.\n\n\nSet an arbitrary positive threshold on the variance\nview_thresholded_eigenspectrum(big_pca, threshold=150)\n\n\n\n\n\n\n\nSetting an arbitrary cumulative variance threshold\nA very commonly used method is to set a threshold based on the cumulative variance of the data: the number of dimensions required to exceed, say 80\\% of the variance, is taken as the latent dimensionality.\n\n\nSet an arbitrary threshold on the cumulative variance\ndef view_cumulative_eigenspectrum(pca: xr.DataArray, *, threshold: float = 0.8) -&gt; mpl.figure.Figure:\n    fig, ax = plt.subplots(figsize=(pca.sizes[\"component\"], 5))\n\n    data = pca[\"eigenvalue\"].copy()\n    data[\"eigenvalue\"] = data.cumsum()\n    data = data.rename({\"eigenvalue\": \"cumulative variance\"})\n    data[\"cumulative proportion of variance\"] = data[\"cumulative variance\"] / pca[\"eigenvalue\"].sum()\n\n    sns.lineplot(\n        ax=ax,\n        data=data.to_dataframe(),\n        x=\"rank\",\n        y=\"cumulative variance\",\n        marker=\"s\",\n    )\n    ax.set_xticks(pca[\"rank\"].values)\n\n    ax_twin = ax.twinx()\n    ax_twin.set_ylabel(\"cumulative proportion of variance\")\n\n    ax_twin.axhline(threshold, ls=\"--\", c=\"gray\")\n    xlim = ax_twin.get_xlim()\n    ylim = ax_twin.get_ylim()\n\n    ax_twin.fill_between(x=xlim, y1=ylim[-1], y2=threshold, color=\"red\", alpha=0.1)\n    ax_twin.fill_between(x=xlim, y1=ylim[0], y2=threshold, color=\"green\", alpha=0.1)\n\n    sns.despine(ax=ax, offset=20)\n    sns.despine(ax=ax_twin, offset=20, left=True, bottom=True, right=False, top=True)\n    ax_twin.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(1))\n\n    fig.tight_layout()\n    plt.close(fig)\n\n    return fig\n\n\nview_cumulative_eigenspectrum(big_pca)\n\n\n\n\n\n\n\nEyeballing the “knee” of the spectrum\nWhen the number of latent dimensions is low, eigenspectra often have a sharp discontinuity (the “knee”), where a small number of dimensions have high-variance and the remainder have much have lower variance. The latent dimensionality is then taken to be the number of dimensions above this threshold determined by eye.\n\n\nPlot the apparent knee of the spectrum\ndef view_eigenspectrum_knee(pca: PCA, *, knee: int):\n    fig = view_eigenspectrum(pca)\n    ax = fig.get_axes()[0]\n    ax.plot(\n        knee,\n        big_pca[\"eigenvalue\"].isel({\"component\": big_pca[\"rank\"] == knee}).values,\n        \"o\",\n        ms=30,\n        mec=\"r\",\n        mfc=\"none\",\n        mew=3,\n    )\n\n    ax.axvline(knee, ls=\"--\", c=\"gray\")\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    ax.fill_betweenx(y=ylim, x1=xlim[-1], x2=knee, color=\"red\", alpha=0.1)\n    ax.fill_betweenx(y=ylim, x1=xlim[0], x2=knee, color=\"green\", alpha=0.1)\n\n    return fig\n\nview_eigenspectrum_knee(big_pca, knee=3)\n\n\n\n\n\n\n\nComputing a summary statistic over the entire spectrum\nA metric such as effective dimensionality summarizes the spectrum using an entropy-like measure, taking into account variances along all the dimensions:\n\\text{effective dimensionality}(\\lambda_1, \\dots \\lambda_n) = \\dfrac{\\left( \\sum_{i=1}^n \\lambda_i \\right)^2}{\\sum_{i=1}^n \\lambda_i^2}\n\n\nCompute the effective dimensionality from the spectrum\ndef compute_effective_dimensionality(eigenspectrum: np.ndarray) -&gt; float:\n    return (np.sum(eigenspectrum) ** 2) / (eigenspectrum ** 2).sum()\n\n\nprint(f\"effective dimensionality = {compute_effective_dimensionality(big_pca['eigenvalue']).values.round(2)}\")\n\n\neffective dimensionality = 2.55\n\n\nHowever, keep in mind that this is a toy example with idealized data. As we will see, when using standard PCA on real data it may be impossible to identify a clear distinction between meaningful dimensions and noise."
  },
  {
    "objectID": "pages/introducing_pca.html#further-thoughts",
    "href": "pages/introducing_pca.html#further-thoughts",
    "title": "An introduction to PCA",
    "section": "Further thoughts",
    "text": "Further thoughts\n\nPreprocessing the data\nBefore PCA, it’s often recommended to preprocess the data by Z-scoring each of the input features X – ensuring that they have zero mean and unit variance:\nZ = \\dfrac{X - \\mu}{\\sigma}\n\n\n\n\n\n\nWhen should we standardize the data?\n\n\n\n\n\nOften, PCA is applied to data where the features are fundamentally different from each other. For example, we might have a dataset where the features of interest are the prices of cars (in dollars) and their masses (in kilograms). Since these two features have different units, the variances of the features are not directly comparable – there’s no obvious way to numerically compare a variance of ($20,000)2 in price and a variance of (1,000 kg)2 in mass. Even if the features being compared are all the same, if they are in different units – say euros, dollars, and cents – the raw variances of the data matrix are meaningless.\nSince PCA implicitly assumes that the variances along each dimension are comparable, we can Z-score each of the features before applying PCA to ensure that they are on a common scale.\nNote, however, that this transformation reduces the information in the system – it is possible that the variances of the features are informative.\n\n\n\n\n\nWhat if the stimulus features covary?"
  }
]